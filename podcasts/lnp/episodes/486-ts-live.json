{"v":1,"episode":486,"speakers":["Tim Pritlove","Thomas Lohninger","Ralf Bendrath","Arnika Zinke"],"t":[0,1,3,5,29,51,52,61,61,70,73,86,172,177,222,226,250,252,256,257,286,370,376,478,485,528,541,554,556,576,615,653,657,663,685,846,896,904,905,915,920,924,930,943,951,952,959,965,968,972,981,1000,1003,1030,1045,1049,1051,1054,1066,1067,1072,1084,1101,1108,1256,1259,1262,1267,1326,1328,1339,1352,1354,1391,1406,1422,1428,1432,1453,1467,1469,1471,1473,1501,1528,1552,1578,1594,1598,1598,1607,1658,1685,1687,1693,1716,1718,1719,1849,1863,1867,1876,1882,1900,1906,1996,2012,2016,2035,2045,2047,2077,2081,2084,2086,2090,2096,2148,2211,2212,2224,2230,2277,2279,2309,2313,2362,2373,2392,2394,2397,2403,2568,2569,2809,2927,3145,3166,3187,3191,3194,3197,3281,3321,3337,3485,3489,3498,3501,3574,3618,3645,3717,3719,3775,3811,3833,3863,4092,4109,4142,4146,4220,4302,4527,4547,4592,4603,4640,4649,4650,4677,4685,4691,4716,4736,4745,4847,4847,4899,4900,4958,4960,5128,5132,5246,5302,5333,5399,5447,5507,5515,5518,5530,5535,5584,5590,5595,5619,5698,5728,5734,5780,5831,5868,5871,5909,5926,5962,5974,6050,6052,6119,6143,6201,6215,6220,6221,6222,6241,6286,6423,6424,6492,6508,6518,6523,6528,6529,6537,6787,6865,6964,7010,7017,7025,7033,7050,7050,7168,7282,7284,7389,7437,7439,7463,7465,7501,7543,7557,7587,7589,7595],"s":[0,1,0,1,0,1,0,2,0,3,0,3,0,3,0,3,0,3,0,1,3,0,2,0,2,0,2,0,2,3,2,0,2,0,2,1,2,1,0,2,0,2,0,2,0,2,0,2,0,2,0,2,3,2,0,2,0,2,0,2,0,3,0,2,0,2,1,2,0,3,1,2,1,2,1,2,1,2,3,0,3,0,2,0,1,2,0,1,0,2,3,2,0,2,1,2,1,2,0,2,0,2,0,2,1,2,0,2,0,2,0,1,0,1,2,0,1,2,0,2,0,2,0,3,2,1,2,0,1,0,1,2,0,2,1,2,1,2,0,2,0,2,0,3,2,1,2,3,2,0,2,0,2,3,0,3,2,3,0,3,0,1,2,3,1,3,1,2,1,2,3,2,3,1,2,0,2,0,2,3,2,0,3,2,1,3,1,2,0,3,0,3,0,2,0,2,0,3,0,3,0,1,3,2,1,2,1,2,0,3,1,3,1,3,2,1,2,1,2,1,2,1,2,0,2,0,1,0,1,2,1,3,2,0,2,0,1,2,1,2,1,3,1,2,0,1,3,0,2,0,3,1,0],"x":["Guten Morgen Thomas.","Guten Morgen Tim.","Sag mal, wie ist eigentlich das Wetter in Brüssel?","Das muss noch abgestimmt werden. Wir haben noch kein Tredo-Gergebnis.","Logbuch Netzpolitik Nummer 486 vom 13. März 2024. 2024.\nUnd ja, den Linus, den habe ich mal kurz weggeschickt, damit wir hier uns mal\num die seriösen Themen kümmern können.\nUnd begrüßen natürlich erstmal Thomas. Habt ihr schon gehört? Hallo Thomas.","Hallo. Genau.","Und heute haben wir eine große Runde, nämlich eine große EU-Runde und begrüßen\naußerdem noch den Ralf, Ralf Benrath. Hallo.","Hallo.","Hallo, du warst ja schon mal bei uns und ganz frisch neu mit dabei,\ngrüße ich auch noch die Annika, hallo.","Hallo, servus.","Ja, Annika, Annika Zinke, fangen wir doch mal mit dir kurz an.\nStell dich doch mal bitte kurz vor, dass wir mal wissen, was du so machst und was dich zu uns führt.","Ja, hallo, freut mich sehr dabei zu sein. Genau, also ich bin Annika,\nich komme ursprünglich aus Wien.\nAlso jetzt haben wir heute zwei Quoten Österreicher quasi im Podcast.\nDas kommt wahrscheinlich auch nicht so oft vor. Genau, ich war ursprünglich\nJournalistin in Wien und bin dann über Umwege in Brüssel gelandet.\nWar dann bei Alexandra Gese als Praktikantin im Office und habe dort auch begonnen,\nan Digital Services Act zu arbeiten.\nUnd bin dann in die Fraktion gewechselt, vor zweieinhalb Jahren in der Fraktion\nder Grünen und war dort zuerst Beraterin für horizontale Digital-Koordinierung.\nDas heißt quasi über die verschiedenen Ausschüsse übergreifend alles,\nwas Digitalpolitik trifft, zu\nkoordinieren und im Rahmen dessen auch recht stark KI-Gesetz gearbeitet,\nweil das natürlich über sehr viele verschiedene Ausschüsse drübergegangen ist,\nweil das ein Thema ist, das nicht unbedingt in einen Ausschuss gut reinpasst.\nUnd bin seit gut einem Jahr jetzt im Binnenmarktausschuss, was einer der zwei\nfederführenden Ausschüsse im KI-Gesetz auch ist, über das wir heute noch sprechen werden.\nGenau, und habe aber unter anderem auch an anderen Files gearbeitet,\nwie zum Beispiel im European Media Freedom Act, der heute auch im Plenum abgestimmt wurde.\nIm Cyber Resilience Act habe ich auch ein bisschen mitgearbeitet.\nGenau, also alles, was quasi Digitalpolitik betrifft und Binnenmarkt irgendwie\nbetrifft, fällt in meinen Ressort.","Was war denn so uninteressant am Journalismus, dass du die Politik gewechselt bist?","Es war nicht unbedingt uninteressant, aber zum einen, wie es für viel bewusst\nist, ist der Journalismus ein recht prekäres Arbeitsumfeld.\nDas war also einer der Hauptgründe. Und der andere Grund war auch,\ndass dadurch, dass wir sehr viel online gearbeitet haben,\nich großes Interesse daran hatte, besser nachzuvollziehen, beziehungsweise mehr\ndaran zu arbeiten, wie Plattformen eigentlich Inhalte verbreiten,\nverbreiten, mehr Richtung eben Empfehlungsalgorithmen zu arbeiten.\nUnd deswegen habe ich dann auch, ja, war ich sehr interessiert,\nam Digital Services Act zu arbeiten, habe dazu auch meine zwei Masterarbeiten geschrieben.\nAlso die Digitalpolitik hat mich im Rahmen meiner journalistischen Karriere\nquasi immer mehr begleitet, sodass ich dann so interessiert daran war,\ndass ich mir dachte, okay, ich möchte hauptberuflich daran arbeiten.","Okay. Masterarbeit in was?","Also es waren zwei zum Digital Services Act, weil ich habe dann schon nicht genug davon bekommen.\nAlso beim einen ging es darum, wie Initiativberichte im EU-Parlament,\nob die eine Auswirkung auf die Kommissionsvorschläge haben können.\nUnd das habe ich im Rahmen des Digital Services Act gemacht.\nUnd bei dem anderen ging es mehr um Empfehlungsalgorithmen und wie die Digital\nServices Act reguliert werden.","Und das war dann für Politikwissenschaft?","Genau, Politikwissenschaften und internationale Beziehungen.","Okay.","Wir haben heute ja sehr viele EU-Themen. Da können wir gleich einsteigen.\nEin Initiativbericht, weil das ist auch ein Begriff, der gerade gefallen ist.\nDas sind einfach nicht bindende Resolutionen, könnte man sagen,\ndie das Parlament erlässt.\nAlso das sind fast die einzige Sache, die das Europaparlament von sich aus machen\nkann und initiieren kann, die halt zur Meinungsbildung dienen sollen.\nWas hat denn deine Masterarbeit ergeben? Haben sie einen Impact gehabt?","Genau, es ist so, dass das Parlament ja kein Vorschlagsrecht hat,\nim Gegensatz zur Kommission, die die Gesetze ja vorschlagen darf.\nUnd von allein hat am Anfang ihres Mandats\nangekündigt, dass sie die Initiativberichte mehr ernst nehmen wird.\nUnd das, was meine Forschung ergeben hat, ist, dass es zwar...\nIn der Theorie nicht übernommen werden muss, in der Praxis es aber schon der\nKommission etwas bringt, wenn die Mehrheiten in den Initiativberichten geformt\nwerden, auch berücksichtigt werden im Vorschlag.\nDas heißt natürlich, wenn man möchte, dass der Vorschlag in irgendeiner Weise\nErfolg hat, ist es nicht dumm, sich anzusehen, wie Mehrheiten im Parlament gebildet werden.\nUnd natürlich, wenn das Parlament dann genau zu einem bestimmten Bereich etwas\nveröffentlicht, dann schon einen Einfluss.\nAber grundsätzlich ist es halt schon so, dass viele von den Initiativberichten\nauch nicht, vor allem Initiativberichte, die jetzt nicht unbedingt auf ein Gesetz\nspezifisch ausgerichtet sind, nicht unbedingt den Erfolg haben,\nden sich manche Politiker inne erhoffen.\nAlso man muss da schon auch ein bisschen differenzieren und es ist nicht so,\ndass jeder Initiativbericht mit dem Strichpunkt übernommen worden ist.\nAber gerade beim Digital Services Act, was ja auch ein sehr großes Gesetz war,\nwar das ein bisschen anders, würde ich sagen.\nAber vielleicht mal greife ich noch, was zu sagen, weil Ralf schon länger im Parlament ist als ich.","Ja, genau, Ralf, sag doch mal was. Du darfst dich auch noch mal vorstellen.","Ja, danke auch noch mal für die Einladung. Ich bin, genau wie Annika,\nFraktionsreferent der Grünen-EFA-Fraktion im Europäischen Parlament.\nIch bin für den Ausschuss für Bürgerliche Freiheiten, Justiz und Inneres zuständig\nund mache da vor allem Datenschutz.\nDas ist der Ausschuss, der auch federführend für Datenschutz zuständig ist.\nNebenbei aber alles, was an anderen Digitalsachen so anfällt,\ninklusive auch Polizeiinformationsaustausch, polizeiliche und justizielle Zusammenarbeit und solche Sachen.\nIch mache aber inzwischen relativ viel auch ausschussüberschreitende Arbeit,\nweil jetzt inzwischen die Kollegen alle mitgeschnitten haben,\ndass ich hier der Onkel Ralf von der DSGVO bin.\nIch habe früher für den Berichterstatter Jan-Philipp Albrecht bearbeitet,\nals das Ding verhandelt wurde und habe seitdem sogar einen IMDb-Eintrag.\nUnd jetzt kommen die Kollegen immer und haben irgendwas zu europäischer Sozialversicherungskarte\nim Beschäftigungsausschuss oder zu Veröffentlichung von Agrarzuschüssen im Agrarausschuss\noder zu irgendwelchen anderen Themen,\nwo es irgendwie dann auch Datenschutzfragen plötzlich gibt.\nIch gehe jetzt zum Financial Information Access Geschichte, Finanzdatenraum\nund komme immer, Ralf, kannst du hier mal drüber gucken?\nUnd das ist ganz, bis zur Fischerei ging das schon. Das ist irgendwie ganz lustig\nmanchmal. Dann lernt man auch viel über den Tellerrand hinaus.\nJa, und ich habe jetzt die Freude gehabt, mit Arne quasi die letzten,\nweiß nicht, drei Jahre oder so zusammenzuarbeiten am KI-Gesetz,\nam Artificial Intelligence Act, weil...\nJa, da kommen wir später zu. Die Details dazu spreche ich mir für nachher.\nAber warum das ein gemeinsames Ausschussverfahren mit dem Binnenmarkt und dem\nInnenausschuss war, das war eine lustige Geschichte.\nEs gibt noch Axel Voss-Witze später.","Das sind immer die besten. Und hast du auch schon einen Initiativbericht mal angestoßen?","Angestoßen selber nicht.\nVerdoppelt. Wie viel davon jetzt in der KI- Verordnung im IAI-Act gelandet ist,\nich glaube ehrlich gesagt gar nicht so viel, weil die Kommission da einen sehr\nstrikten Rahmen gesetzt hat, aber da gehen wir später noch an die Details.","Nur mal um so ein Gefühl dafür zu bekommen, weil ich habe diesen Begriff Initiativbericht\nehrlich gesagt noch nie gehört, aber wie viele werden denn da so pro Jahr von gemacht?\nIst das so ab und zu mal einer oder passiert das am laufenden Meter?","Nee, das passiert viel viel am Anfang der Legislaturperiode,\nwenn die neue Kommission erst anfängt, ihr Arbeitsprogramm abzuarbeiten und\nbis dann die ersten Gesetzesvorschläge kommen, dauert es meistens eine Weile\nund dann sind die Leute noch übermotiviert und wollen selber was machen.","Hast du so Beschäftigungstherapie fürs Parlament?","So ein bisschen. Die Abgeordneten wollen mal irgendwas sagen,\nohne dass es gleich ein Gesetz ist und dann schreibt man halt so einen Initiativbericht.\nDas ist quotiert. Das können nicht beliebig viele werden.\nIch weiß nicht, ob das in allen Ausschüssen so ist. Bei uns im Innenausschuss\nist es so, dass dass, glaube ich, parallel immer nur sechs gleichzeitig verhandelt werden dürfen?","Ich glaube, die Kapazität hätten wir gar nicht, sechs gleichzeitig zu verhandeln.\nAlso ich glaube, daran scheitert es schon, aber normalerweise kann man die vorschlagen\nund das ist in der Menge begrenzt.\nAber wir hatten zum Beispiel im Binnenmarktausschuss gegen Ende noch einen sehr erfolgreichen,\nInitiativbericht zu Addictive Design, also Abhängigkeit machendem Design,\nsein, hört sich in Deutsch nicht so gut an, wo wir das Feedback auch von der\nKommission bekommen haben, dass das eins der Top-Themen ist,\nan dem die jetzt auch für die nächste Legislaturperiode arbeiten.\nAlso es kommt auch ein bisschen darauf an, in welcher, ob man quasi so ein bisschen\ndas Gefühl hat, in die richtige Richtung quasi zu stechen mit dem Thema.","Also Initiativberichte sind so ein bisschen strikter reguliert.\nDie müssen von der Konferenz der Fraktionsvorsitzenden bewilligt werden.\nWie gesagt, es darf nur sechs parallel laufen, zumindest in meinem Ausschuss.\nAndere Ausschüsse können aber noch eine Beteiligung einfordern und dazu noch\nOpinions machen, die dann irgendwie berücksichtigt werden müssen oder auch nicht.\nDas ist ein bisschen mühsam. In meinem Ausschuss ist es eher so,\nwenn wir irgendwie eine Stellungnahme raushauen wollen, dann machen wir eine Resolution.\nDie wird einfacher verhandelt, die muss nicht genehmigt werden.\nDa gibt es auch keine anderen Ausschüsse, die mit reinquatschen wollen.\nUnd die wird dann quasi vom Liebeausschuss, also Civil Liberties,\nJustice, Non-Fers, direkt im Plenum getabelt. Und dann ist sie meistens nach\neinem Monat schon durch.","Verstehe. Es gibt also sozusagen auch noch kleinere Einheiten von Schlussfassungen.","Ich entdecke nach 15 Jahren hier immer noch Sachen in der Geschäftsordnung,\ndie ich bisher noch nicht kannte.","Na gut, aber wir wollen uns ja heute nicht so sehr mit der Bürokratie an sich beschäftigen,\nsondern mal konkret reinschauen, was derzeit denn eigentlich so alles in der\nPipeline ist, beziehungsweise jetzt gerade beschlossen worden ist oder unmittelbar\nvor dem Beschluss steht, unter anderem den AI-Act.\nAber du, Ralf, hast ja noch ein paar andere Themen auch noch,\ndie du mitgebracht hast.","Ja, das ist so ein bisschen eine Digitalwoche hier im Plenum gerade.\nDeswegen ist Annika ja auch gerade in Straßburg, weil gerade Plenarsitzung des\nEuropäischen Parlaments in Straßburg ist.\nUnd zwei, was heißt kleinere, die nicht so viel Aufsehen erregt haben,\nSachen sind mir hier noch aufgefallen.\nDas ist einmal die Produkthaftungsrichtlinie, die revidiert wurde und der Cyber Resilience Act.\nUnd die führen beide Sachen ein, für die wir damals mit Jan-Philipp Albrecht\nnoch und so schon seit teilweise zehn Jahren gekämpft haben.\nWo man also auch mal schön sehen kann, Politik ist manchmal echt das langsame Bohren dicker Bretter.\nAls wir damals angefangen haben, mit Jan-Philipp Albrecht uns um Produktsicherheit,\nalso Quatsch, IT-Sicherheit mal zu kümmern, kam man ziemlich schnell drauf,\nauch natürlich durch Gespräche mit Linus und anderen vom CCC und so.\nEs gibt keine guten Anreizstrukturen bisher für die Hersteller,\nsich ernsthaft um IT-Sicherheit zu kümmern.\nEs gibt keine Produkthaftung für Software, es gibt keine Verpflichtung,\nSicherheitsupdates zu liefern oder irgendwas.\nSoftware kommt immer mit dieser allgemeinen Terms of Service zum Anklicken,\nich akzeptiere die Software so, wie sie ist.\nUnd keiner ist verantwortlich. Das hat sich jetzt geändert, nach diesen zehn\nJahren oder wie lange da andere Leute schon drüber nachgedacht haben.\nUnd das eine ist die Product Liability Directive, die Produkthaftungsrichtlinie,\ndie gibt es schon ewig, die ist dieses Jahr 39 geworden,\nwurde 1999 mal kurz ein bisschen gänzt, um landwirtschaftliche und Fischereiprodukte mit abzudecken.\nUnd sie sagt im Prinzip, wenn du ein schadhaftes Produkt verkaufst und Leute\nnehmen deswegen Schaden daran, das kann auch mentalen Schaden beinhalten,\ndann bist du verantwortlich und\nmusst dafür haften und im Zweifelsfall Schadensersatz und sowas zahlen.\nUnd jetzt mit der neuen Revision, die gerade gestern angenommen wurde,\nist endlich auch Produkthaftung für Software mit dabei.\nDas heißt, wenn du eine schadhafte Software in den Markt bringst,\nkommerziell, das ist immer nur kommerziell, dann bist du haftbar.\nDas heißt, damit hast du natürlich jetzt als Hersteller einen starken Anreiz,\ndich mal ernsthaft um IT-Sicherheit zu kümmern.\nWas wichtig ist, da gab es auch zwischendurch immer wieder mal Fragen aus der Community, die,\nWenn du ein freier Softwareentwickler bist, der nur zu Hause so ein bisschen\nvor sich hin frickelt und das Zeugs irgendwo auf GitHub hochlädt oder so,\naber das nicht geschäftlich macht, dann bist du nicht in der Verantwortung.\nWenn jemand jetzt dein freies Softwaremodul nimmt und ein kommerzielles Produkt\neinbaut, dann ist der dafür verantwortlich und nicht du als Entwickler von dem\nkleinen Open-Source-Software-Tool.\nDas war also ganz wichtig, das haben wir da auch gewonnen.\nWas sonst? Ja, ich glaube, das waren so die wesentlichen Elemente.","Ja, vielleicht bei dem Punkt. Das war auch etwas, das wirklich gerade bei der\nFree Software Foundation Europe ein riesiges Thema war.\nAlso in der gesamten Community der freien und offenen Software hat man sich\nda große Sorgen gemacht rund um Cyber Resilience Act.\nUnd es ist gut, wenn da jetzt eine Lösung gefunden wurde, die einfach gemeinwohlorientierte,\nnicht kommerzielle Produkte ausnimmt. Und ich frage mich dann immer so,\nwie stabil sind die Definitionen? Ist das wirklich gut abgegrenzt?\nUnd de facto, was du damit natürlich dann auch hast, ist, dass die Person,\ndie daraus ein Geschäft macht, auf einmal natürlich auch alle etwaige Haftung\nübernimmt und die nicht weitergeben kann an irgendwen.\nWas, glaube ich ja auch, wenn wir so beim ersten drüber nachdenken,\neine brauchbare Lösung ist.\nEin anderes Thema, was beim Cyber Resilience Act noch ganz… Thomas.","Wir waren noch bei der Produkthaftungsrichtlinie. Cyber Resilience Act habe\nich mir gar nicht vorgestellt. Aber es geht sehr ineinander über.","All the same.","Also kurze Anmerkung dazu. Also diese Product Liability Directive,\ndie gibt es ja im Prinzip schon.\nDie ist bloß 40 Jahre alt und seitdem nicht wirklich angefasst worden,\nwenn ich das richtig sehe.","Doch, es wurden 1999 landwirtschaftliche und Fischereiprodukte mit reingetan.","Aha.\nDeine neue Kernkompetenz sozusagen.","Aber sonst nichts. Und jetzt die\ngroße Neuerung ist eben, dass jetzt auch digitale Produkte mit drin sind.","Ah, okay. Und was heißt das dann konkret? Also ich meine, wenn ich jetzt sozusagen\nWindows benutze und dann mentalen Schaden davon trage, was ich durchaus für\nwahrscheinlich halte, dann kann ich dann sozusagen Bill Gates anrufen und der\nmuss mir dann Rente zahlen.","Naja, wenn dann die entsprechenden Gerichte, wo das wahrscheinlich landen wird,\nentscheiden, dass das Produkt schadhaft war und du deswegen einen mentalen Schaden\ndavon getragen hast, dann ja.","Verstehe.","Halte ich aber den Fall eher für unwahrscheinlich. Es gibt sozusagen kaputte\nSoftware, die einfach Sicherheitslücken und ähnliches hat.","Ja, und das heißt, hat das den Status einer Verordnung? Gilt das sozusagen unmittelbar dann?","Das ist eine Richtlinie, die muss durch nationales Recht umgesetzt werden.","Okay, und das heißt, das kann auch noch ein bisschen dauern, sozusagen.","Ja, da fragst du mal die FDP, wie lange die wieder auf die Bremse treten will.\nDas ist ja hier inzwischen ein Running Gag, hätte, hätte Lieferkette.","Ja, genau. Okay, gut, aber nehmen wir jetzt mal an, es sei im Sinne des Gesetzes\nin eine Richtlinie überführt worden bereits.\nKannst du mal so einen typischen Fall aufmachen, den ihr sozusagen bei dem Design\nim Sinn hattet und wie sich das dann äußern könnte konkret?","Annika, hast du da mehr mit zu tun gehabt? Weil das ja euer Ausschuss war.","Es war mein Ausschuss, aber es war mein Kollege, der daran gearbeitet hat.\nAber es ist zum Beispiel jetzt nicht KI, nur um das ganz kurz zu sagen,\nweil für KI war eigentlich ein Schwestergesetz vorgesehen, nämlich die KI-Haftungsrichtlinie.\nDie steckt aber momentan im Justizausschuss fest, da ist der Berichterstatter Axel Voss.\nAlso da gab es etwas Ungereimtheiten, was die Ausrichtung des Gesetzes betrifft.\nAber ja, ich habe nicht in der plattbaren Produkthaftungsrichtlinie gearbeitet.","Ja, ich habe die jetzt auch nicht im Detail verfolgt. Ich habe vor allem das\nBriefing von unserem Kollegen dazu gelesen.\nAlso auch nicht den ganzen Gesetzestext. Aber so ein Beispiel,\nwas ich mir jetzt da vorstellen würde, ist, wenn du dir einen Smart Thermostat\nkaufst für deine Heizung.","Ja, habe ich gerade gemacht. Sehr gut. Viel Spaß.","Wer klemmt denn bitte sein Haus ans Internet?","Dann mit dem Internet hat das einfach nichts zu tun.","Ach so, okay. Aber wenn das Ding sozusagen Internet-Konnektivität hat und sich\nda jemand reinhackt und irgendwie deine Heizung so hoch dreht,\ndass der Boiler kaputt geht oder sowas, dann wäre der Thermostat-Hersteller dafür haftbar.","Wow.","Wenn sozusagen dem nachzuweisen ist, dass er hier ein schadhaftes Produkt auf den Markt gebracht hat.","Aber mit dem Nachweis, das könnte natürlich dann nochmal so ein Ding werden.\nDas muss sich dann erst mal noch zeigen vor den Gerichten, was für Nachweise\ndort erbracht werden müssen.\nOder gibt es dafür auch dann schon eine Maßgabe, wie das zu erfolgen hat?","Es gibt bei bestimmten Fällen eine Umkehrung von der Beweislast.\nDie bestimmten Fälle müsste ich aber nachschauen. Aber es gibt Fälle,\nwo es für den Konsumenten sehr schwierig nachzuweisen ist, wo das umgekehrt\nwird und auch in Fällen, wo es eben besonders schwer der Schaden wäre.","All right, gut. Dann können wir ja auf den Cyber Resilience Act kommen,\nRalf. Was hat es denn damit auf sich?","Genau, das ist ein neues Gesetz. Das ist eine Verordnung, gilt also unmittelbar,\nnachdem sie jetzt veröffentlicht wird und dann in Kraft tritt.\nUnd da geht es sozusagen nochmal härter wirklich in die Pflicht für Anbieter\nvon elektronischen Endgeräten. Das kann auch Software beinhalten oder andere digitale Devices.\nDas ist so ein bisschen ähnlich aufgehängt wie das KI-Gesetz,\nder AI-Act im Rahmen dieses sogenannten New Legislative Framework,\nwo noch so ein ganzer Rattenschwarz von Marktaufsichtsbehörden dranhängt und\nso und am Ende das CE-Label rauskommt, was man so kennt als Label für Produktsicherheit in Europa. Ja.\nDie Hersteller von solchen Produkten,\nalso das ist eine relativ allgemein gehaltene Regelung, Artikel 13,\nObligations of Manufacturers, also Auflagen für Hersteller, die müssen sich\nan die essentiellen, ich weiß immer nicht, was du auf Deutsch hast,\nwir machen alles auf Englisch hier, Essential Requirements,\nessentielle Anforderungen, danke, in Annex 1 halten.\nUnd Teil 1 von Antrag 1 ist über Cyber Security.\nUnd da steht dann ganz klar drin, Produkte mit digitalen Elementen sollen designt,\nentwickelt und hergestellt werden, sodass sie ein angemessenes Level von Cybersicherheit\nbasierend der jeweiligen Risiken liefern.\nUnd sie sollen zum Beispiel auf den Markt gebracht werden ohne bekannte Sicherheitslücken.\nAlso versteckte Backdoors, die der Hersteller kennt, aber nicht angibt beim\nVerkauf, sind jetzt damit verboten offiziell.\nSie müssen bei Default einer sicheren Konfiguration ausgeliefert werden.\nSie müssen Sicherheitsupdates kriegen können. Sie müssen vor ungesichertem Zugriff\ngeschützt sein und wenn es einen Zugriff geben sollte, müssen Sie es berichten.\nUnd jetzt steht sogar noch drin, Sie müssen die Vertraulichkeit von gespeicherter\noder übertragener Daten,\negal ob persönliche Daten oder andere, sicherstellen, unter anderem durch Verschlüsselung,\nSpeicher und auch Transit. Ja.\nUnd die Sicherheitsupdates müssen mindestens für fünf Jahre bereitgestellt werden.\nAußer das Produkt hat absehbar eine deutlich geringere Lebenszeit,\ndann reicht es auch kürzer.\nAber mindestens sind erstmal normalerweise fünf Jahre müssen verpflichtende\nSicherheitsupdates geliefert werden.","Fünf Jahre ab was? Ab was gerechnet?","Ab Verkauf. Ab Verkauf. Verstehe ich zumindest so.","Also das ist wirklich so wie ein Mindesthaltbarkeitsdatum, nur diesmal wirklich\nfür Sicherheitsupdates. Genau.","Und die sagen auch ganz deutlich da, ich glaube in einem Erwägungsgrund,\nich finde den Teil gerade jetzt nicht mehr sofort,\nwenn klar ist, dass das Gerät eine längere Lebenszeit hat, zum Beispiel Router\noder andere Sachen, die normalerweise länger laufen als fünf Jahre,\ndann müssen die Sicherheitsupdates auch jetzt für die erwartbare Lebenszeit geliefert werden.\nWas da jetzt noch nicht drin ist, das hatten wir mit Linus damals mal diskutiert\nbei einer Anhörung unserer Fraktion zur IoT-Sicherheit, kurz nach dem WannaCry-Unglück.\nWas passiert, wenn diese Lebenszeit erreicht ist, End of Life,\nund die keine Sicherheitsupdates mehr liefern? Wann müssen sie dann sozusagen\ndem Nutzer es ermöglichen, das Produkt selber up-to-date, wenn zum Beispiel\ndie Software unter freie Lizenzen gestellt werden muss oder so. Das ist hier noch offen.\nDas ist nicht geklärt. Du hast einfach nur jetzt mindestens fünf Jahre die Updates.\nWenn das Produkt absehbar länger hält, dann auch noch länger.\nJa, und danach kannst du es dann wegschmeißen oder auf eigenes Risiko weiter benutzen.\nAber das ist wirklich ein ziemlicher Durchbruch, finde ich. Das muss man echt mal anerkennen.","Das würde ich auch meinen.","Es war tatsächlich ein Änderungsantrag im Binnenmarktausschuss,\ndas unter einer freien Lizenz zu veröffentlichen, wenn es nicht mehr am Markt\nist. Leider hat es keine Mehrheit bekommen.","Ja, solche Sachen werden nie verstanden. Aber jetzt mal praktisch gefragt,\nwenn du sagst Mindeststandards bei IT-Sicherheit, so peinliche Dinge wie ungehäschte\nPasswörter, das dürfte es dann nicht mehr geben, oder?","Nee. Nee.","Und etwas, an das ich mich auch noch erinnere, wir haben am Anfang an dem Gesetz gearbeitet,\nda gab es ja auch diese Meldung von Sicherheitslücken, wenn ein Hersteller jetzt etwas findet,\neine Lücke in der eigenen Software oder in den eigenen Geräten,\ndass diese Lücken dann auch an staatlichen Stellen unmittelbar gemeldet werden\nmüssen, auch noch bevor die Sicherheitslücke behoben wurde.\nWo es dann ja auch die Sorge gab, dass dieses Wissen um etwaige Einfallstore\ndann von staatlichen Stellen vielleicht sogar auch missbraucht würde für zum\nBeispiel Staatstreuer.","Ja, ich habe den Text jetzt nicht vor mir, aber wie ich den Briefing vom Kollegen\nChristian entnehme, gibt es jetzt anscheinend eine neue Stelle bei der EU-IT-Sicherheitsagentur\nEnisa, die genau diese Sicherheitslücken bekommen soll.","Ja, das war nämlich wirklich ein bisschen problematisch, weil damit natürlich,\nwenn du konkret den Weg, wie deine Software aufgemacht werden kann,\nsofort melden musst, noch bevor du es geschlossen hast.\nAlso das widerstößt dann ein bisschen gegen, Sponsor-Predisclosure ist das jetzt\nnicht, aber es öffnet gewisse Gefahren.","Okay, ob man die bevor man es gepatcht hat schon melden muss,\nweiß ich jetzt nicht. Das müsste man im Detail nochmal nachgucken.\nDas habe ich jetzt nicht vor mir.","Das war zumindest früher mal ein Problem. Ab wann gelten denn diese Gesetze?","Der Cyber Resilience Act, wie gesagt, ist eine Verordnung, die gilt unmittelbar.\nDie ist jetzt quasi heute, gestern angenommen worden im Plenum.\nDas muss jetzt der Rat formal noch annehmen, weil wir noch im ersten Lesungsverfahren sind.\nDann wird es im Amtsblatt der EU veröffentlicht. Und dann weiß ich nicht,\nob es irgendwelche Übergangsfristen gibt oder ob das dann sofort gilt.\nSteht jetzt hier nicht im Briefing drin.","Also meines Wissens nach gibt es relativ lange Übergangsfristen.\nAlso zumindest nachdem es aus dem Parlament kam, haben wir sehr große Probleme\ngehabt, die Fristen nicht allzu lange zu haben.","Also ein paar Jahre, oder was muss man sich da jetzt vorstellen?","Ja, genau, ein paar Jahre.","Okay, das tropft also so langsam rein.","Okay, ich sehe gerade Artikel 14, Reporting Obligations of Manufacturers.\nDa geht es offenbar nur um Verwundbarkeiten, die aktuell aktiv ausgenutzt werden.\nWenn also gerade irgendwie Angriffe laufen, dass dann die nationalen C-Cert-Koordinatoren\nund Enisa benachrichtigt werden sollen, damit die Schritte ergreifen können.\nWenn gerade ein Angriff läuft, macht das ja auch Sinn.\nAber darüber hinaus sehe ich jetzt keine Verpflichtungen.","Zumindest gibt es jetzt erstmal nicht mehr das Admin-Admin-Standardpasswort\nbei irgendwelchen Routern.\nDas ist schon mal wichtig, dass mal überhaupt so eine Linie da gezogen wird mit so Leuten.\nAlso wenn ihr hier irgendwie mitspielen wollt, dann ist einfach mal ein gewisses\nMinimum jetzt auch definiert und nicht nur so der Markt macht das schon.\nUnd ich denke, das ist dann doch schon ein wichtiger Schritt nach vorne.","Ja, und vor allem auch, Ralf hat ja schon die Analogie mit dem CE-Label genannt.\nGenauso wie man sich darauf verlassen muss, dass ein Gerät, das an Strom hängt,\nnicht zum Rauchen anfängt und explodiert, es hat auch bei der Netzwerkverbindung\nein gewisses Mindestmaß an Sorgfalt einfach geboten.\nAlso ob dieses Gesetz wirklich in allem perfekt ist, wird man sehen,\naber die Richtung ist da schon die richtige, glaube ich.","Und hier gab es natürlich auch wieder die Frage, was ist mit Open Source?\nDer gleiche Ansatz wieder bei der Produkthaftungsrichtlinie.\nWenn man Software nicht kommerziell auf den Markt bringt, ist man raus.\nAlso der kleine Open-Source-Entwickler, der irgendwelche Tools baut,\ndie dann andere kommerzielle Hersteller nehmen, der ist raus und die kommerziellen\nHersteller sind in der Pflicht.\nUnd die müssen dann sozusagen auch für die Sicherheitsupdates sorgen,\nnicht der kleine Bastler in der Kellerwerkstatt oder so.","Aber was definiert denn dann kommerziell? Also es gibt ja auch oft so Leute,\ndie Open Source machen und dann quasi selber kommerziell sind,\nweil sie dann Beratungen dafür machen.\nDamit wären sie ja sozusagen im kommerziellen Spiel.","Oder um Spenden bitten für ihre Software.","Graubereich.","Puh, das weiß ich nicht. Annika, das ist wahrscheinlich in deinem Ausschuss\nschon besser ausdiskutiert. Das wüsste ich jetzt nicht. Gibt es bestimmt irgendwo\nschon Standarddefinitionen?","Es gab dazu lange, ich weiß, es gab dazu sehr lange Diskussionen,\ngab auch beim Cyber Veselians Act und auch gerade was Spenden betrifft,\nvor allem Spenden, die immer wieder über einen längeren Zeitraum passieren,\nauch von größeren Entitäten.\nIch weiß jetzt aber auch nicht, was genau das Endresultat war,\nweil wir natürlich, wenn es noch im Parlament ist, relativ viel eingebunden sind.\nAber wenn das dann final in den Trilog geht, vor allem war das auch zu einer\nZeit, wo das KI-Gesetz gerade im Trilog war, Da sind wir dann auch als nicht\nfederführende Ausschüsse ein bisschen raus.\nAber an sich wurde sich jetzt auf eine Definition geeinigt, mit der meines Wissens\ndie Open-Source-Community recht zufrieden ist und die jetzt eigentlich auch\nin den meisten neuen Digitalgesetzen verwendet worden ist, wo relativ klar ist,\nwas ist wirklich auf den Markt bringen und was ist, wenn man es nur eben zum\nBeispiel bei GitHub hochlädt.","Ich habe hier gerade herausgefunden, Erwägungsgrund 15, da steht was drin,\ndie, ich muss jetzt sozusagen live vom Englischen ins Deutsche übersetzen,\ndie Lieferung im Kurs einer kommerziellen Aktivität kann charakterisiert werden,\nnicht nur indem ein Preis für ein Produkt mit digitalen Elementen verlangt wird, sondern auch,\nwenn man einen Preis verlangt für technische Unterstützungsdienste.","Das würde das dann mit einschließen.","Well, this does not serve only the recuperation of actual costs.","In einer der letzten Folgen haben wir Gesetze durch JGPT analysieren lassen.\nDiesmal lassen wir sie durch die Verhandler selbst interpretieren. Ein Fortschritt.\nAber das ist auch passend irgendwie zu dem nächsten Gesetz, das wir noch kurz\nansprechen wollten, Ralf.\nDas ist auch etwas, was du uns mitgebracht hast. Das hat ja fast schon irgendwie\nden guten Nachrichtsjingel verdient.","Die Plattform-Workers, ne?","Ja, genau.","Genau. Es gibt jetzt auch seit dieser Woche eine Plattform, die wurde nicht\nim Plenum abgestimmt, sondern die war schon im Februar ausverhandelt und war\nbisher aber im Rat blockiert.\nUnd gerade jetzt vorgestern am Montag hat wieder der Ministerrat für Beschäftigung,\nSoziales, Gesundheit und Verbraucherschutz getagt.\nUnd da gab es bisher eine Sperrminorität, bestehend aus Estland,\nGriechenland, Frankreich und Deutschland, mal wieder die FDP.\nUnd Estland und Griechenland haben jetzt sich von der Enthaltung zu einem Vote,\nzu einer Abstimmung dafür durchgerungen.\nDeswegen gab es jetzt nur noch mit Frankreich und Deutschland alleine keine Sperrminorität mehr.\nUnd deswegen kommt jetzt die Platform Workers Directive,\ndie erstmals sozusagen die Arbeitsbedingungen regelt für Leute,\ndie über Plattformen, was weiß ich, wie Uber Eats oder Deliveroo oder sowas\narbeiten, aber auch zum Beispiel Mechanical Turk von Amazon oder so Zeug.\nWeil da bisher immer noch ganz oft unklar war, sind das Angestellte,\nsind das Freelancer, welche Rechte haben die gegenüber dem Quote-unquote Arbeitgeber und so.\nUnd diese Plattform Worker's Direct, soweit ich es verstanden habe,\nwie gesagt, das war Beschäftigungsausschuss, ich habe es auch nur von der Seite\nmitverfolgt, die macht jetzt vor allem zwei Sachen, die...\nSagt eben, dass sozusagen erst mal die Annahme gilt, wenn man so ein Plattform-Worker\nist, ist man Angestellter.\nUnd die Beweislast, dass das nicht der Fall ist, hat der Arbeitgeber sozusagen oder die Plattform.\nDas heißt, damit gelten dann die ganzen Rechte als Arbeitgeber wie Recht auf\nbezahlten Urlaub, Recht auf Streik und alles mögliche andere,\nKrankengeld und so weiter.\nUnd wie gesagt, wenn die Plattform meint, nee, aber in dem Fall ist das doch\nganz klar nur ein Freelancer, der macht nur ab und zu mal hier was,\nwenn er Bock drauf hat, dann muss sie das eben nachweisen.\nUnd dann ist sie raus aus den Arbeitgeberverpflichtungen.\nUnd das Zweite ist, dass es jetzt zum ersten Mal Regeln gibt für algorithmisches\nManagement von Arbeitern oder Arbeitenden.\nDas heißt, wenn man ernsthafte Entscheidungen trifft über so einen Plattformarbeiter\noder eine Arbeiterin, zum Beispiel Beendigung des Vertrages oder so,\ndas darf auf keinen Fall von einem Algorithmus gemacht werden,\ndas muss immer ein Mensch entscheiden.","Gilt denn, also für welche Unternehmen gilt denn das und für welche Mitarbeiter gilt denn das?\nAlso inwiefern ist jetzt die Zugehörigkeit oder der Aufenthalt in Europa da\nentscheidend oder gilt das dann irgendwie weltweit oder wie ist das gedacht?","Das gilt immer nur für Europa. Europäische Gesetz gilt nur in Europa.","Klar, aber gilt es auch für einen indischen Plattformarbeiter,\nfür eine Firma, die in Europa ist?","Gute Frage. Kann ich jetzt so nicht beantworten. Wie gesagt,\ndas habe ich selber nicht verhandelt.","Und gilt es für einen deutschen Mitarbeiter einer indischen Firma zum Beispiel\noder einer amerikanischen?\nAlso das ist so das, was ich mich frage. Was ist jetzt da sozusagen, wen betrifft das quasi?\nUnd wann ist man dadurch geschützt?\nWeil so viele Plattformen haben wir ja nicht in Europa.","Muss ich mal kurz gucken, ob das von der Kollegin hier im Briefing irgendwie\nabgedeckt ist, sonst wüsste ich es nicht.","Also es ist ganz oft so bei diesen grenzüberschreitenden Arbeitsverhältnissen,\ndass es sehr schnell sehr kompliziert wird, auch innerhalb der EU.\nDa gibt es auch recht komplizierte Regelwerke, so Stichwort Entsenderichtlinie.\nAber wovon man auf jeden Fall ausgehen kann,\nist, dass die klassischen Essensauslieferer, Leute, die in der Servicebranche\nüber Plattformen beschäftigt sind,\nalles, was eben über die klassischen Apps bezogene Arbeitsleistung ist, mehr oder weniger,\nhier auf jeden Fall davon enthalten ist.\nUnd die Gewerkschaften jubeln hier auf jeden Fall.\nMan sollte anmerken, dass schon vor dem Konflikt, den Ralf gerade genannt hat,\nes hier eine Abschwächung gab zwischen dem, was das Parlament verabschiedet hat.\nDa hätte es so einheitliche Kriterien gegeben, ab wann du denn jetzt wirklich\nangenommener fixer Angestellter von dieser Plattform bist. ist.\nUnd diese Kriterien gibt es jetzt aber leider nicht mehr. Nur noch Prinzipien,\naber da gibt es dann Umsetzung, Spielraum.\nDas hier ist ja eine Richtlinie, die muss erst in nationales Recht überführt werden.\nUnd das wird zu einem Fleckerteppich führen, wo einfach in unterschiedlichen\nLändern unterschiedliche Kriterien gelten.\nUnd das ist für das Land kann das immer noch gut sein, wenn man jetzt hier es\nschafft, Druck zu machen.\nAber es gibt kein europaeinheitliches Niveau, ab wann der Uber-Treiber,\nder Uber-Fahrer könnte jetzt zum Beispiel in Deutschland Status A haben und\nin Österreich Status B zum Beispiel.","Es gibt sogar, habe ich jetzt gelernt, keine einheitliche Definition von was\nWork, also Arbeit, eigentlich genau bedeutet, weil das anscheinend EU-weit bisher\nnicht harmonisiert ist und die Mitgliedstaaten wohl darauf bestanden haben,\ndass Arbeitsrecht und sowas weiterhin nationale Kompetenz ist.","Das könnte die Sache ein bisschen schwierig machen, oder?","Ja, wie Thomas sagt, das wird einen Flickenteppich geben, aber besser so ein\nFlickenteppich als gar keine Rechte für die Plattformarbeiter, ganz klar.\nWas ich gerade noch gesehen habe hier im Briefing der Kollegin ist,\ndass die Plattformen auch jetzt Kommunikationskanäle bereitstellen müssen,\ndamit die Plattformarbeitenden untereinander kommunizieren können,\nzum Beispiel um Betriebsräte zu gründen oder sowas.","Ah ja. Okay, aber das sind so einfach mal so die typischen Tages,\nweil das erste Beispiel mit diesem Mechanical Turk, da denkt man ja dann gleich\nirgendwie Amazon und Ausland und so.","Aber… Amazon hat eine Niederlassung in Europa.","Ja klar, aber diese Mechanical Turks sind ja sozusagen traditionell sehr weit\nüber den Planeten verstreut gewesen,\naber es ist natürlich klar, dass jetzt vor allem so Lieferdienste,\nwas Thomas schon sagte oder eben sowas wie Uber,\ndavon dann vermutlich auch betroffen sein wird.\nNur, dass man es mal zuordnen kann, was davon wirklich dann tangiert ist.\nWeil Plattform ist ja dann ein dehnbarer Begriff.","Was mal konkret, ist Onlyfans davon betroffen?","Du hast Sorgen.","Sag ja nur.","Vermutlich schon. Ich meine, Sexarbeit ist auch Arbeit.","Ja, stimmt. Sind die da nicht alle selbstständig?","Was man vielleicht einfach noch vermelden sollte oder dazu sagen ist,\ndass das auf jeden Fall ein Schritt in die richtige Richtung ist.\nUnd ich glaube auch, dass da die Gewerkschaften schon einen wichtigen Schritt tun,\nweil gerade freie DienstnehmerInnen oder Selbstständige waren ja oft auch bei\nden klassischen Arbeitsrechten diejenigen, die durch die Finger geschaut haben\nund nicht mal repräsentiert wurden.\nUnd denen einfach hier zu einem besseren Status zu verhelfen, ist auf jeden Fall gut.\nUnd Und zuletzt nochmal jetzt dadurch, dass das auf diese Art jetzt irgendwie\ndurchgegangen ist, es zeigt auch irgendwie schön, dass die Achse Deutschland-Frankreich\nalleine dann doch nicht verhindern kann.\nUnd dass sich alle anderen Staaten hier schon darauf einigen konnten.\nAlso da kann man den Liberalen wahrscheinlich danken, die in Deutschland die.\nZustimmung verhindern und in Frankreich ja an der Regierung sind.","Ja, aber das kann man vielleicht nochmal kurz ein bisschen vertiefen,\nWeil das ist echt ein Problem inzwischen mit diesem sogenannten German Vote,\nwas in Brüssel hier inzwischen alle kennen.\nUnd das ist einfach ein Fehler im Koalitionsvertrag in Berlin.\nDas gibt es ja oft auch in Landesregierungen oder Landeskoalitionsverträgen,\ndass da drin steht, wenn die Regierungsparteien sich nicht einigen können auf\nirgendeine Sache, enthalten sie sich im Bundesrat.\nSo, im Bundesrat reicht aber normalerweise eine einfache Mehrheit,\num ein Gesetz zu beschließen.\nRat der Minister der Europäischen Union brauchst du eine qualifizierte Mehrheit.\nDa brauchst du irgendwie 72 Prozent der Mitgliedstaaten und die 65 Prozent der\neuropäischen Bevölkerung repräsentieren. Ich glaube, so in der Größenordnung.\nUnd das heißt aber dann, eine Enthaltung ist dann genauso scheiße wie ein Dagegenstimmen,\nweil einfach diese qualifizierte Mehrheit nicht zustande kommt.\nDas heißt also, wenn die FDP als kleinster 4-Prozent-Koalitionspartner in Berlin\nsagt, wir sind dagegen, dann muss die Regierung sich enthalten,\nlaut Koalitionsvertrag, und arbeite dann aber aktiv gegen so ein Gesetz und\nenthält sich nicht nur einfach so, ne?","Das nennt man German Vote?","Ja, weil das einfach jetzt in ganz vielen Gesetzen passiert,\ndass die Deutschen sich enthalten und damit dazu beitragen, dass vielleicht\neine qualifizierte Mehrheit nicht zustande kommt, weil die FDP dagegen ist.\nHätte, hätte, Lieferkette.","Und das ist sozusagen ein Konstruktionsfehler im Koalitionsvertrag,\ndass man es für Europa nicht anders geregelt hat.","Genau. Und das ist auch ein Konstruktionsfehler im Bundeskanzleramt, würde ich mal sagen.\nAlso unter Merkel wäre das nicht so durchgegangen, weil das einfach massiv die\ndeutsche Rolle auch in der Europäischen Union untergräbt.\nAlso Deutschland, auch bis zu Merkel und so, war immer eigentlich dafür bekannt,\ndass man versucht hat, einen Ausgleich zu finden zwischen den Mitgliedstaaten,\ndass man nicht so selber mit dicken, ausgefahrenen Ellenbogen in den Verhandlungen\nreingegangen ist und einfach versucht hat, den Laden zusammenzuhalten.\nIdealerweise gemeinsam mit Frankreich. Und wenn jetzt dank der FDP die Deutschen\nda immer so rumpoltern müssen und immer sagen,\nwir sind aber dagegen de facto und im Zweifelsfall so ein Gesetz blockieren,\nweil dann kommen natürlich viele kleinere Mitgliedstaaten auch oder auch Frankreich\ndann, die sich hinter Deutschland dann verstecken.\nUnd das ist einfach echt ziemlich bitter.\nUnd wie gesagt, in Brüssel schon bekannt als The German Vote.","Annika, du hast da noch was zu sagen?","Nein, ich wollte nur sagen, dass genau wie Ralf das angesprochen hatte,\nwenn natürlich Deutschland und Frankreich beide sagen, sie sind dagegen oder\neiner enthält sich, der andere ist dagegen, dann kreiert das einen Effekt auch\nbei den anderen Mitgliedstaaten.\nDas heißt, die überlegen sich dann schon, vielleicht sollten wir doch dagegen\nstimmen oder schauen wir uns das nochmal genauer an, warum denn die zwei Großen da dagegen stimmen.\nUnd wir hatten das Problem auch in dem KI-Gesetz letztlich, dass wegen Deutschland\nund wegen der FDP das Gesetz und die Abstimmung im Rat auf der Kippe gestanden sind.","Wegen Deutschland und Frankreich.","Ja, zitiere ich dann nochmal den griechischen Arbeitsminister von den Konservativen.\nDa wir im Geist von Kompromiss und europäischer Einheit arbeiten wollen,\nwerden wir die Richtlinie unterstützen. Sehr schön.\nUnd ja, das obliegt dann wirklich den Regierungen oder eben den Koalitionsabkommen,\nwie das genau gehandhabt wird. In Österreich ist es zum Beispiel in der aktuellen\nRegierung so, dass man sich da bewusst nicht abstimmt.\nAlso hat man auch wegen Klimaschutz gemacht, dass da sozusagen die grüne Klimaministerin\nsich austoben kann, ohne dass hier irgendjemand reinredet, was die Ratspositionen betrifft.\nIst dann aber zum Beispiel bei Überwachungsthemen unter Umständen sehr negativ,\nwenn du keinen Ausgleich hast und das dann der konservative Innenminister selber\nalles entscheiden kann. Aber ja, das ist Europa.","In Deutschland ist es so, die SPD-Innenministerin entscheidet das Asylpaket\nmit und die Grünen schlucken es.\nNaja, anderes Thema.","Okay, aber soviel jetzt zur Platform Workers Directive. Jetzt gibt es demnächst\nPorno-Betriebsräte, das ist doch super.\nSo, ein weiteres Thema noch vor dem AI-Act hast du noch für uns,\nnämlich die Health-Plattform, nein, wie heißt es, Entschuldigung.","European Health Data Space.","Der European Health Data Space, korrekt.","Genau, das hast du verhandelt. Also, worum geht es dabei? Ich glaube,\ndas hatten wir in Ansätzen, aber give us the primal.","Ja, das ist auch wieder ein Gesetzesvorschlag,\nder in zwei Ausschüssen gleichberechtigt verhandelt wird.\nIn meinem Ausschuss Liebe, also Civil Liberties, Justice and Home Affairs,\nwegen der Datenschutzkomponente und Gesundheit- und Umweltausschuss wegen Gesundheit, Gesundheitsdaten.\nUnd das ist kurz vorm Abschluss. Morgen Nacht soll der letzte Trilog,\nalso die letzte Verhandlungsrunde zwischen Rat, Parlament und Kommission stattfinden.\nDas Ding hat im Prinzip zwei Elemente. Ist natürlich viel komplizierter,\naber hat im Prinzip zwei Elemente. Das eine ist Regeln für primäre Nutzung von\nGesundheitsdaten und das andere ist für sekundäre Nutzung.\nPrimäre Nutzung heißt, wenn mein Arzt meine Patientenakte Akte irgendwie lokal\nauf dem Rechner schon elektronisch vorhält,\ndann soll er oder sie die in der Regel auch vernetzt bereitstellen,\ndamit wenn ich dann zu einem anderen Arzt gehe oder zu einer anderen Ärztin\noder ins Krankenhaus oder so, die auch Zugriff auf die gesamte Akte haben und\ndas eben besser nutzen können, um mich besser zu behandeln, weil die dann auch\nVorerkrankungen und vorherige Behandlungen und sowas direkt sehen können.\nMacht irgendwie Sinn, das gibt es hier zum Beispiel in Belgien auch.\nDa Da sind viele Leute auch ganz glücklich drüber. Da kann man auch selber mit\nder App auf dem Smartphone irgendwie\ngucken, was ist eigentlich gerade in meiner Patientenakte so los?\nDann kann ich die Sachen auch selber mal rauspulen und angucken und so.\nDa war lange der Streit, braucht es dazu ein Opt-in? Also müssen die Leute einwilligen,\ndamit es elektronisch vernetzt verfügbar gemacht wird?\nOder ist es generell bei Default so und man soll vielleicht nur widersprechen können?\nIn Deutschland ist, glaube ich, aktuell der Stand, dass es immer noch ein Opt-in\nist, aber das soll jetzt umgestellt werden auf Opt-out unter lauter Wacht,\ndamit mehr Leute die elektronische Patientenakte nutzen.\nUnd das Gesundheitswesen sozusagen effektiver ist. Das Ergebnis hier ist im\nPrinzip das gleiche. Es bleibt erstmal so vorgesehen, dass es per Default in\neine vernetzte elektronische Gesundheitsakte kommt.\nDie Mitgliedstaaten können dann selber aber noch entscheiden,\nob sie ein Opt-out ermöglichen wollen oder nicht.\nSo, das ist eigentlich noch relativ unproblematisch. Da gab es dann so ein bisschen\nMissverständnisse in den Verhandlungen, weil die Leute, die Belgier hier von\nder Ratspräsidentschaft, haben erst gedacht, wenn man da widerspricht,\nheißt das, dass der Arzt gar nicht mehr meine Akten elektronisch führen kann,\nsondern wieder auf Papier zurück muss.\nDas war natürlich dann so, nee, Quatsch. Natürlich kann der Arzt seinen lokalen\nRechner haben. Wir sind 2024 heutzutage.\nNur die sollen nicht vernetzt sein.\nWenn man als Patient vielleicht besondere Sicherheitsbedürfnisse hat,\nweil man auch mal eine psychologische Behandlung hatte oder andere Sachen oder\neine Abtreibung oder so, will man einfach, dass das nur beim Arzt in der Praxis\nliegt und nicht vernetzt ist.\nNicht irgendwie vielleicht auch sogar Angreifer da rangehen können oder so mit\nIT-Sicherheitslücken. Obwohl, die sind ja jetzt alle weg mit dem Cyber-Resilienz-Experiment.","Gott sei Dank.","So, das ist das erste, primäre Nutzung.\nDas zweite ist die sekundäre Nutzung und das ist für uns das Riesenproblem,\nweil es gibt eigentlich jetzt seit über 2400 Jahren den hypokratischen Eid,\nden Ärzte ablegen müssen und der beinhaltet unter anderem die ärztliche Schweigepflicht\noder das Patientengeheimnis.\nDass einfach das, was ich mit meinem Arzt bespreche, zwischen uns bleibt und\nich darauf vertrauen kann.\nWas jetzt hier vorgesehen ist, ist, dass die Gesundheitsdaten,\nsofern sie vernetzt verfügbar sind, auch für andere Zwecke genutzt werden können.\nDas geht dann vor allem um Forschung. Natürlich Big Pharma hat da auch ein Rieseninteresse\ndran, aber auch öffentliches Gesundheitsmanagement, zum Beispiel in Zeiten von\nPandemien, Infektionstracing, solche Geschichten, was ja teilweise die Gesundheitsämter\nauch heute schon machen.\nEs gibt ja Sachen, wo die ärztliche Schweigepflicht unterbunden wird durch Gesetz,\nbei meldepflichtigen Krankheiten und so, wie es zum Beispiel Corona auch war.\nUnd da war jetzt aber die Riesenfrage bis zum Schluss oder ist immer noch,\ndas Parlament wollte hier aber dann mindestens sagen, dann sollen die Leute\naber zumindest ein Widerspruchsrecht haben.\nDass ich sagen kann, meine Patientendaten sollen bitte für Forschung oder so\nnicht bereitgestellt werden.\nDie Mitgliedstaaten haben jetzt, die belgische Ratspräsidentschaft hat wirklich\nversucht, das irgendwie zu berücksichtigen.\nDas war für das Parlament sozusagen die eine große rote Linie die ganze Zeit.\nWir haben ganz viele andere kleinere Sachen aufgegeben, um dieses Opt-out zu\nkriegen für sekundäre Nutzung.\nAber die Mitgliedstaaten stellen sich jetzt auf stur und sagen,\nnö, wir wollen einfach alle Daten und man kann gerne ein Opt-out machen,\naber dann gibt es für die Mitgliedstaaten dann das Recht, wieder das Opt-out zu überschreiben.\nAlso das gilt dann einfach nicht. Und das sind dann auch für Zwecke,\nwo ich mich frage, braucht es dazu wirklich immer alle Daten?\nUnter anderem für öffentliche Institutionen, die ein Mandat im Bereich der öffentlichen\nGesundheit haben oder sogar private Institutionen, die eine Aufgabe im Bereich\nder öffentlichen Gesundheit haben.\nGut, da könnte man vielleicht noch drüber streiten, ob man das ein bisschen\nenger fasst und dann ist es vielleicht noch akzeptabel.\nDer Parlamentsvorschlag war jetzt, dass man das nur in Situationen von öffentlicher\nmedizinischer Notlage oder Notlage der öffentlichen Gesundheit machen kann.\nSo eine ähnliche Regelung haben wir schon im Data Act zum Beispiel.\nDann wollen sie aber auch noch alle möglichen Research, medizinische Produktentwicklung\nmedizinische Geräteentwicklung also die haben sie bisher auch so entwickeln\nkönnen ohne dass man von allen Patienten die Daten abgegriffen hat und das letzte ist auch Statistiken.\nNationale, multinationale und EU-Level offizielle Statistiken ich meine Statistiker\nkönnen seit über 100 Jahren mit unvollständigen Datensätzen umgehen,\ndas ist deren Job da dann irgendwie die Bias so rauszurechnen,\nJa, so sieht es aus. Das ist das letzte Angebot, was die Kommission jetzt auf\nden Tisch vorgelegt hat als Quote-Unquote-Kompromiss.\nDas geht morgen Abend in den letzten Trilog. Heute war nochmal ein Treffen der\nSchattenberichterstatter vom Parlament von den verschiedenen Fraktionen.\nUnd es sieht so aus, dass die Mehrheit, zumindest eine Mehrheit aus EVP,\nEKR, also die europakritischeren Konservativen und Sozialdemokraten,\ndas so akzeptieren will.\nUnd im Prinzip alles aufgibt, was wir die ganze Zeit gesagt haben.\nHier, wir geben euch die ganzen anderen Sachen nur, wenn wir dieses eine Opt-out\nkriegen, aber dann auch richtig.\nUnd am Ende werden wohl nur die Grünen und die Linken dagegen stimmen.\nID ist noch ein bisschen unklar. Die würden normalerweise als gute Populisten\nauch irgendwie auf den Zug aufspringen und sagen, da sind wir dagegen.\nWir verkaufen nicht unsere Gesundheitsdaten an Big Pharma.\nAber die haben zufälligerweise die Berichterstatterin, Liebe Ausschuss,\nweil das sonst niemand wollte.\nUnd das ist per Dehont bei denen gelandet. Und da sehe ich jetzt nicht,\ndass die da großen Rückzieher macht, wenn sie selber Co-Berichterstatterin ist. ist.\nAber verhandelt wurde es im Prinzip alles von dem EVP Berichterstatter im Umwelt-\nund Gesundheitsausschuss.\nJa, das ist das. Morgen Abend geht das den Bach runter.","Ja, noch nicht. Also gibt man einen Brief, aber ich wiederhole jetzt nochmal oder fasse zusammen.\nAlso wir haben ein EU-Gesetz, das die Digitalisierung von allen Patientinnenakten\nund wahrscheinlich auch sonstigen.\nGesundheitsbezogenen Daten aus dem in Krankenhäusern, Arztpraxen und sonstigen\nEinrichtungen miteinander vernetzt.\nOpt-out oder Opt-in kann es geben, wenn der Mitgliedstaat das vorsieht für diese Primärnutzung.\nAber bei der Sekundärnutzung, die eigentlich ja die kritischere ist,\nweil da geht es nicht nur um das Gesundheitssystem, sondern da geht es um Forschung.\nUnd das heißt auch pharmakologische Forschung. Das heißt auch,\ndass hier ganz viele andere Interessenträger auf einmal Zugriff auf sehr sensible Daten bekommen.\nWir haben auch schon mehrmals diskutiert, dass solche Gesundheitsdaten sehr\nschwer bis gar nicht zu anonymisieren sind, weil das ist einfach sehr einzigartig bei Menschen.\nWenn ich als Arbeitgeber weiß, wenn du im Krankenstand bist,\nwenn du geimpft wurdest oder du das auf Social Media postest,\nfinde ich dich wieder in diesen Datensets.\nEs gibt dazu auch eine Klage meines Wissens von der GFF,\ndie da auch in Deutschland höchstgerichtlich dagegen vorgehen,\ngegen diese Sekundärnutzung anhand von einem Menschen, der halt sehr einzigartige\nBlutwerte oder sonstige Werte hat und da auch sehr leicht zu reidentifizieren ist.\nDas halte ich für eine ganz große Gefahr. Das ist vielleicht auch nochmal zu\nsagen, das hier ist so eine sogenannte Lex Spezialis zur DSGVO, oder?\nDas etabliert eine Ausnahme von unserem Grundrecht auf Datenschutz für diesen eigenen Bereich hier.\nUnd ich meine...\nAlso morgen wird das sozusagen, kannst du da vielleicht auch mal aus dem Nähkästchen\nplaudern, wie läuft denn sowas ab, so eine Trilog-Sitzung, also wie viele Leute\nsind da im Raum, wie lange wird da verhandelt, was erwartet dich da morgen?","Morgen könnte es relativ schnell gehen. Also der letzte Trilog letzten Donnerstagabend,\nder hat um 18 Uhr angefangen, war ungefähr morgens um fünf zu Ende ohne Ergebnis,\nweil das Parlament da noch die Linie gehalten hat.\nUnd jetzt haben aber alle Fraktionen intern nochmal geguckt,\nsind wir noch ein bisschen flexibler oder so. Die Mitgliedstaaten dagegen haben nicht geguckt.\nEs gab heute noch mal Sitzung der Botschafter.\nDa war das Thema gar nicht auf der Tagesordnung.\nAlso die Belgier haben gar nicht erst versucht, noch mehr Flexibilität für sich\nselber zu kriegen, sondern haben nur gesagt, hier, liebes Parlament,\nwenn ihr noch mal flexibler werdet, dann können wir es nächste Woche noch mal versuchen.\nWeil morgen ist sozusagen die letzte Deadline, um vor der Europawahl noch ein Gesetz abzuschließen.\nWeil das dann alles noch irgendwie sprachlich aufgeräumt werden und noch abgestimmt\nwerden muss und so weiter.\nAlso morgen kann es relativ schnell gehen. Da sitzt dann normalerweise der belgische\nMinister, Gesundheitsminister, die Berichterstatter vom Parlament,\nvielleicht noch ein Vorsitzender oder Vize-Vorsitzender vom Umweltausschuss.\nDer Vorsitzende vom Innenausschuss kommt zu solchen Verhandlungen nie,\nobwohl das könnte. Das ist aber ganz gut so, weil der ist immer so ein bisschen verwirrt.\nDer könnte da nur Unsinn reinbringen. Und dann sitzen da halt noch die Kommission,\ndas ist dann wahrscheinlich die Kommissarin,\nKiria Kiedis, die Gesundheitskommissarin, und alle Fraktionen,\nmanche mit Abgeordneten richtig vertreten, viele aber, weil jetzt gerade Straßburg-Woche\nwar und die schon längst ihre Flüge nach Hause gebucht hatten in die ganzen\nMitgliedstaaten und so, die werden jetzt nicht morgen alle nach Brüssel fahren.\nAlso von uns wird auch keiner dabei sein, weil die alle Verpflichtungen schon woanders hatten.\nAber dann sitze halt ich da mit meiner Kollegin aus dem Umwelt- und Gesundheitsausschuss,\nunserem digitalen Koordinator, der Nachfolger von Arneka an dem Job,\nFrancesco, noch ein paar Abgeordneten, Mitarbeitende.\nJuristische Dienste sind da immer vertreten, oft auch die Sprachjuristen. Das sind dann so...\n20 bis 30 Leute vielleicht in so einem Setting. Und reden tun aber eigentlich\nnur der Rapporteur, also der Berichterstatter,\nin diesem Fall eigentlich in der Regel der ENVI, also Gesundheits- und Umweltausschuss-Rapporteur\nvon den Konservativen, der belgische Minister und die Kommissarin. darin.\nUnd dann gibt es manchmal so Punkte, wo man dann sagt, okay,\ndas Parlament muss sich mal kurz zurückziehen,\ndann gibt es nebenan irgendeinen sogenannten Breakout-Room, wo dann sogar so\nein Patrick Breyer zum Beispiel, der das für uns auf der Datenschutzseite macht,\nsich online dazuschalten kann und dann wird halt intern in einer Parlamentsdelegation\nberaten, okay, Leute, wir haben jetzt hier ein neues Angebot von den Belgiern,\nkönnen wir das irgendwie mittragen oder ist das immer noch nicht gut genug,\nkönnen wir einen Gegenvorschlag machen oder so.\nUnd dann müssen halt sozusagen die Fraktionen der Reihe nach sagen,\nwie weit sie gehen können.\nUnd dann muss der Berichterstatter gucken, wie er damit umgeht,\nob er jetzt eine Mehrheit findet für den Kompromiss oder nicht.\nManchmal gibt es auch Situationen, wo der Berichterstatter einfach sagt,\nich habe jetzt hier keine klare Mehrheit, ich lasse es einfach darauf ankommen.\nWir nehmen das Ding jetzt mal so an und gehen damit in die Ausschüsse und dann\nins Plenum und gucken, ob wir eine Mehrheit kriegen. Das ist aber eher selten.\nDas kann aber teilweise bei komplexeren Gesetzen, hier sind jetzt noch ein paar\nFragen offen, unter anderem auch die Frage der Lokalisierung,\nweil das EP die Daten in Europa speichern wollte und nicht irgendwo auswärts.\nUnd der Rat sagt aber, nee, nach DSPVO kann man die doch auch in den USA transferieren,\nweil da gibt es ja eine Angemessenheitsentscheidung und so. Also das sind aber\nnur vier, fünf Punkte, die noch offen sind.\nDie kann man morgen relativ schnell abkaspern, weil eigentlich fast alle außer\nuns und den Linken schon angedeutet haben heute Morgen, dass sie da mitgehen können.\nEs gibt auch andere Beispiele. Da können wir vielleicht gleich zum AI-Act noch\nwas zu erzählen, weil da haben wir, glaube ich, den bisher längsten Trilog gehabt.\nDer hat insgesamt 39 Stunden gedauert.","Darauf kommen wir gleich. Aber ich will nur kurz innehalten,\ndass das so kurz vor einer Europawahl ziemlicher Wahnsinn ist,\nals hier eine Massenenteilung von Gesundheitsdaten irgendwie auf den Weg zu\nbringen. Also eigentlich müsste das doch morgen scheitern.\nUnd wenn es das nicht im Trilog tut, dann hätte man nur noch die Chance,\ndas im Plenum in zweiter Lesung zu verhindern, oder?","In erster Lesung. Wir sind noch im First Reading Procedure. Es geht dann also\njetzt Ende April ins Plenum, ja. Das letzte Plenum vor der Europawahl.\nDa könnte man noch einen Antrag stellen, das muss man gar nicht,\nman kann auch dagegen stimmen.\nUnd wenn eine Mehrheit der Abgeordneten dagegen stimmt, dann ist es tot,\nklar. Aber das sehe ich einfach nicht.\nAber macht gerne Kampagne. Wir sind dabei.","Vielleicht hilft ja die German Vote am Ende.","Nee, in dem Fall hat Deutschland damit kein Problem.","Okay.","Das war eher so, dass man irgendwie dann aus Verhandlerkreisen im Rat hört,\ndass die deutschen Vertreter oder Vertreterinnen einer Ratsarbeitsgruppe, das ist ja SPD,\nLauterbach, Gesundheitsminister, dass die sich dann abschätzig über den Bundesdatenschutzbeauftragten\nUlrich Kelber äußern, der auch SPD-Mitglied ist, weil die sich anscheinend mit\ndem inzwischen so überworfen haben, dass sie über ihn nur noch schlecht reden können.\nAlso unsäglich.\nVielleicht noch kurz eine Klarstellung, damit das nicht in den falschen Hals kommt.\nEs ist schon so, das muss man auch anerkennen, dass die Daten,\nwenn sie für sekundäre Nutzung freigegeben werden, da muss erst ein Antrag gestellt\nwerden und die sogenannten Health Data Access Bodies, also in der Regel irgendwelche\nAbteilungen im Gesundheitsministerium oder so, müssen das dann genehmigen.\nDie Daten werden dann nicht einfach an Big Pharma übermittelt,\nso als riesengroßer Patentendatensatz, sondern die werden nur von dem Health\nData Access Body in einem sicheren Processing, in einer sicheren,\nDatenverarbeitungsumgebung, Secure Processing Environment, bereitgestellt und\nda muss sozusagen dann der Antragsteller kommen und seinen Algorithmus zu den\nDaten bringen. Der kriegt aber die Daten nicht mit nach Hause geliefert.\nAlso die Daten gehen sozusagen nicht raus, Aber es sind natürlich trotzdem meine\nDaten und ich als Patient will selber entscheiden können, ob die irgendjemand\nfür Forschungszwecke oder so verarbeiten kann, egal wo und unter welchen Umständen.","Alright. Gut, dann schlage ich mal vor, schlage mal hier das Buch erstmal zu,\nzu dem Thema und kommen auf unseren Kernthema, der AI-Act. Perfekt.\nUnd Annika, da bist du ja sehr engagiert gewesen, wenn ich das richtig verstanden habe.\nKannst du vielleicht mal anfangen und nochmal kurz erläutern,\nwas so die Genese dieses Acts war?\nAlso was genau ist hier der Trigger gewesen, damit es überhaupt dazu kam?\nUnd was sind sozusagen die politischen Zielsetzungen, die sich hier letzten\nEndes Bahn gebrochen haben?","Also vielleicht mag Ralf die Genese kurz machen, weil ich möchte nicht über\neine Zeit reden, wo ich noch nicht da war und Ralf war schon dabei.\nDeswegen kann Ralf vielleicht kurz die Genese machen und ich kann das Gesetz\nkurz erklären dann und was alles dann während der Verhandlungen passiert ist.","Das fing schon vor ein paar Jahren an, ich glaube nach einer letzten Legislatur\nsogar, da gab es einen Initiativbericht im Rechtsausschuss von Mehdi Delvaux\naus Irland, der hieß zu Robotics and Civil Liability.\nDa wurde unter anderem diskutiert, ob wenn ein Roboter oder eine KI selbstständig\nEntscheidungen trifft, ob die dann nicht auch selber wie eine Art juristische\nPerson werden sollte, die dann auch Verantwortlichkeit dafür kriegt und sowas.\nWo dann zum Glück am Ende der Diskussion rauskam, nein, ganz klar,\ndie Verantwortung liegt immer bei einem Menschen.\nEine KI kann nicht für irgendwas verantwortlich gemacht werden.\nDie kann ja auch nicht in den Knast gehen oder so. Jemand würde das nichts ausmachen.\nAber die hatte einen ganz schönen Einstieg damals in ihren Erwägungsgründen.\nDa stand dann unter anderem drin, dass vom klassischen Pygmalion-Mythos der\nAntike über Frankensteins Monster von Mary Shelley und der Prager Golem-Legende\nbis zum Roboter von Karel Čapek,\nder dieses Wort geprägt hat, Menschen über die Möglichkeit fantasiert haben,\nintelligente Maschinen zu bauen.\nIn den meisten Fällen Androiden mit menschlichen Zügen.\nFand ich mal einen schönen Einstieg in so einen Initiativbericht,\nso ein bisschen poetischer als normal.\nSo, und dann ging so ein bisschen hier überall, das hieß damals teilweise noch\nBig Data, wurde überall darüber diskutiert, dass man jetzt Möglichkeiten hat,\nmit den großen Datenmengen auch viele Maschinen zu trainieren und damit lustige Sachen zu machen.\nUnd dann hat die Kommission, die hatte vorher noch so eine High-Level-Expert-Group\neingerichtet und so weiter, dann hat die Kommission angekündigt,\nsie werden ein Gesetz vorlegen zum Thema KI-Regulierung, das erste weltweit.\nUnd dann wurde hier plötzlich hektische Betriebsamkeit ausgelöst.\nDa haben, glaube ich, in sieben Ausschüssen wurden dann Initiativberichte gemacht,\nalso von Grundrechteaspekten über Bildung bis hin zu Sicherheit und Verteidigung\nund so, wo überall KI vielleicht eine Rolle spielen könnte und was man da machen sollte.\nUnd parallel gab es noch einen Sonderausschuss zum Thema KI,\nwo Axel Voss von der CDU Berichterstatter war.\nAuch ein bisschen bescheuerte Doppelarbeit. Da macht man sieben Initiativberichte\nparallel und noch einen Sonderausschuss parallel.\nAber irgendwie wollte die Mehrheit im Haus das so.\nUnd Axel Voss hat dann in seinem Berichtsentwurf versucht, so ein bisschen auch\nMady Delvaux mit ihrem Roboterbericht zu imitieren, in dem auch ein bisschen\npoetisch wurde. Aber der hat dann einfach nur Unsinn reingeschrieben.\nDa stand dann zum Beispiel drin, dass KI das fünfte Element sein wird,\nneben Erde, Wind, Feuer und Wasser, was uns immer umgeben wird und so.","Schon fast homöopathisch, okay. Okay.","Also, naja, und dann kam der Kommissionsvorschlag für das Gesetz,\ndas war etwa vor drei Jahren, ne?\nAnnika, ich weiß gerade gar nicht mehr.","Ja, vor drei Jahren im April 2021. Genau.","Dann kam der Vorschlag und dann hat relativ schnell der Justizausschuss Axel\nVoss zum Berichterstatter gemacht für die Gesetzgebung.\nUnd dann haben aber alle anderen Fraktionen sich plötzlich zusammengetan und\nhaben eine neue Fraktion gegründet, die sogenannte ABV Group, Anybody But Voss.\nEs wollte einfach niemand außer Axel Voss selber, dass er der fehlerführende\nBerichterstatter im fehlerführenden Ausschuss wird. Deswegen war klar,\nder Rechtsausschuss ist schon mal raus.\nUnd dann wurde ziemlich lange hin und her verhandelt.\nUnd am Ende, so wirklich am letzten Tag der Deadline, glaube ich,\nkam dann in der Konferenz der Fraktionsvorsitzenden ein Vorschlag von den Sozialdemokraten,\ndass doch ein gemeinsames Verfahren werden sollte zwischen dem Ausschuss für\nbürgerliche Freiheiten, Justiz und Inneres, weil der für die Grundrechte zuständig ist,\nund dem Binnenmarktausschuss,\nweil die Kommission dieses KI-Gesetz auch in Form von so einem,\nauf den Markt bringen Gesetz, was für Regeln muss ich einhalten,\nwenn ich KI auf den Markt bringen will, vorgeschlagen hat.\nUnd das waren dann am Ende federführende Berichterstatter, Sozialdemokraten\nim Binnenmarktausschuss und Liberale im Grundrechte- und Innenausschuss.\nSo kam das.","Das ist also alles sozusagen auch von dieser europäischen Sicht des Maschinenmenschen,\nso Frankenstein und so weiter. Wir haben ja im Westen eine sehr negativ konnotierte\nSicht auf diese ganze… Hast du recht, ne?\nNaja gut, ich meine, gehen wir mal nach Japan, da ist einfach eine ganz andere Grundhaltung dazu.\nDa hast du sozusagen so die Maschine, der Freund des Menschen und wann auch\nimmer Robotik in Japan ein Thema ist, dann geht es immer sofort um Assistenzsysteme,\nhelfen, Pflege und so weiter.\nDas ist so das, was da immer im Vordergrund steht und es hat natürlich auch\nviel mit so einer kulturellen Prägung zu tun, die hier definitiv ein bisschen\ndystopischer ausfällt als jetzt in anderen Kulturen.","Ja, aber es passt auch, glaube ich, ganz gut in die Linie der ganzen europäischen\nDigitalgesetzgebung der letzten fast zehn Jahre jetzt, was sozusagen mit der\nDatenschutzgrundverordnung ja angefangen hat und dann mit dem Digitalen Dienste\nGesetz, Digitale Märkte Gesetz,\nData Act, Data Governance Act und so weiter, oder jetzt hier Cyber Resilience Act,\ndass man einfach nach und nach jetzt besser verstanden hat, was sind denn wirklich\ndie echten Risiken und Gefahren bei den ganzen neuen Technologien,\nvor allem, wenn die in der Masse ausgerollt werden und jetzt versucht,\nlangsam mal die Sachen wieder einzufangen.","Das ist aber ein guter Punkt, weil während wir bei den anderen Sachen ja schon\ndas auch alles sehr lange beobachten oder jetzt verhältnismäßig lange,\nja, also das Internet und so Computer etc., das ganze Digitalwesen begleitet uns ja jetzt,\nsagen wir mal, die europäische Gesellschaft vielleicht aktiv seit Mitte der\n90er Jahre so wirklich, würde ich mal sagen, ungefähr. ungefähr.\nUnd jetzt haben wir natürlich auch schon eine gewisse Zeit gehabt.\nWährend jetzt dieses AI-Thema ist ja relativ frisch.\nAlso im Vergleich zu den anderen Themen habe ich so den Eindruck,\nwird das relativ früh aufge...\nAlso das wird nicht mal ein relativ schneller Vorstoß. Sonst sagt man immer,\nja, die Politik reagiert ja nicht und jetzt ist das für uns schon alles so die\nRealität und die Politik kommt nicht mit.\nUnd jetzt habe ich so fast so den Eindruck, jetzt schlägt es komplett um und\njetzt wird AI zu einem Zeitpunkt reguliert,\nwo glaube ich noch nicht mal eine wirklich klare Vorstellung davon existiert,\nwas es jetzt eigentlich genau ist oder macht oder was jetzt wirklich die realen\nBedrohungen und Chancen und Risiken sind,\num in dieser klassischen Abwägungsgeschichte zu bleiben.","Ja, da hast du sicher recht.","Ja, und das war, glaube ich, auch sehr bewusst so gemacht, weil eben auch auf\ndie konstante Kritik irgendwie reagiert wurde, dass wir immer so spät dran wären.\nAlso gerade bei dem Digitalen Dienstegesetz war es ja auch so,\ndass es hieß, ja, also wir haben so verschiedenste Probleme,\ngerade mit den großen Plattformen.\nUnd warum braucht da die EU so lange?\nUnd das war dann schon irgendwie so ein selbsterklärtes Ziel,\nauch von von der Leyen da wirklich irgendwie fortzubreschen und irgendwie mit\ndiesem Brussels-Effekt quasi zu reiten und da für KI was vorzulegen.\nWobei ich finde allein der Name AI Act, und es wurde auch viel kritisiert,\nnicht ganz unproblematisch ist, weil es ja eigentlich auch um automated decision making geht,\nbeziehungsweise, ja, dass auch nicht ganz klar war, ob dann automated decision\nmaking auch in dem Begriff Artificial Intelligence fällt oder nicht.\nAber AI Act klingt halt besser als automated decision making law.\nAlso das war auch ein bisschen ein PR.","Ja, guter Punkt. Genau. Und das ist ja dann wiederum etwas, was schon länger diskutiert wird.\nMan sieht das ja hier auch so Algorithm Watch und ähnliche Gruppen haben sich\nja da auch schon lange mit dieser Problematik beschäftigt.\nAlso wer fällt die Entscheidung und damit natürlich auch verbunden,\nwer ist am Ende haftbar für falsch getroffene Entscheidungen und das hinterfragt\nhalt sowohl einfache Algorithmen,\ndie nun durch AI gleich nochmal ein Level weniger nachvollziehbar werden potenziell.","Genau. Und es ist jetzt so, um kurz das Gesetz zu erklären,\nalso ich würde sagen, es ist jetzt im Vergleich zu den anderen Gesetzen vielleicht\netwas innovationsfreundlicher gedacht worden,\nin dem Sinne, dass in dem Gesetz eben auch diese, zum Beispiel diese innovativen,\nich weiß gar nicht den Begriff, aber Sandboxes heißt es auf Englisch, Sandkisten.","Reallabore heißen die auf Deutsch.","Noch nachgeschöpft werden muss. Also es gab quasi ein eigenes Kapitel für Measures\nfor Innovation, um eben auch die quasi so ein bisschen industriepolitisch auch\nzu mehr KI-Systeme in Europa zu generieren.\nWeil im Vergleich dazu zum Beispiel die Systeme, die verboten werden,\nim Kommissionsvorschlag ja eigentlich sehr dünn waren.\nAlso es gab ein Verbot für biometrische Massenüberwachung in Echtzeit,\naber dann auch wieder mit ziemlich großen Ausnahmen. Unter anderem,\nwenn man zum Beispiel Missing Children, also Kinder sucht.\nEs gab ein Verbot für Social Scoring, das aber so limitiert geschrieben war,\ndass es eigentlich wirklich nicht wirklich was anwendbar gewesen wäre.\nWäre, klingt aber gut, wenn man eine PR-Mitteilung dazu macht.\nUnd dann das, was die KI-Provider, also die Hersteller, danke.\nEs ist wirklich manchmal schwierig, wenn man immer in Englisch arbeitet und\ndann versucht, alles auf Deutsch zu übersetzen.\nGenau, also dass die Hersteller einfach eigentlich nur dann etwas zu erfüllen\nhatten, wenn sie als Hochrisiko eingestuft wurden.\nDas heißt, es gab zwar diese Pyramide, die vielleicht auch einige schon gesehen\nhaben, quasi welche Bereiche das KI-Gesetz quasi umfasst.\nUnd oben auf der Pyramide sind die verbotenen KI-Systeme, was ja eigentlich\nde facto so gut wie nichts ist.\nDann gibt es quasi einen mittleren Bereich mit Hochrisiko, wo dann alles,\nwas quasi zu erfüllen ist im KI-Gesetz, quasi nur in diesem Bereich fällt und\nalle Regelungen quasi nur in dem Bereich zu erfüllen sind.\nUnd dann gibt es noch einen untersten Bereich, das ist Low-Risk oder Minimum-Risk,\nalso quasi die wenigst Risiko-KI-Systeme, die ein paar Transparenzpflichten erfüllen mussten.\nDas heißt, diese Pyramide, die die Kommission da quasi auch vorgestellt hat,\nist eigentlich recht verwirrend, weil letztlich ist es ein Gesetz für ein paar\nPseudoverbotene KI-Systeme gewesen und das, was sie als Hochrisiko begriffen haben.\nUnd der Begriff Hochrisiko ist ja auch eigentlich recht problematisch,\nweil da will ja auch kein Hersteller eigentlich reinfallen.\nAlso kein Hersteller, der sein KI-System irgendwie schon verkaufen will,\naußer es ist wirklich für einen Bereich, der hochproblematisch ist,\nmöchte wirklich in den Hochrisikobereich fallen.\nUnd das ist, glaube ich, auch ein Begriff, der uns negativ durch die ganzen\nVerhandlungen verfolgt hat.\nGenau, nur um das fertig zu erklären, was Hochrisiko ist und was nicht,\nist in dem sogenannten Annex Free,\nwenn ich das richtig im Kopf habe, festgeschrieben, das sind quasi verschiedene\nBereiche, die von Bildung bis Migration, Arbeitsverhältnisse gehen,\nwo verschiedene Kaisersysteme,\nStrafverfolgung genau, reingegeben\nwurden, die potenziell in diesen Hochrisikobereich fallen könnten.\nUnd genau, also das ist so mal ein bisschen die Logik und auch nochmal darauf\nzurückzukommen, was Ralf vorhin gesagt hat,\nes ist eben in diesem Produktsicherheitsgesetzesrahmen eingebettet worden.\nDas heißt, KI wird als Produkt begriffen, was auch schon nicht ganz unproblematisch ist.\nUnd das wurde auch, also man munkelt, dass es auch deswegen gemacht wurde,\ndamit das Gesetz eben nicht nur im Justizausschuss landet, sondern eben auch\nim Binnenmarktausschuss, wo ja alles, was Produktsicherheit betrifft, behandelt wird.\nAlso das ist auch schon bewusst von der Kommission so gewählt worden,\nnicht unbedingt, weil sie KI unbedingt als Produkte sehen wollten,\nsondern auch, weil man dann vielleicht,\nund das sieht man auch bei anderen Gesetzen, schon beeinflussen will,\nin welchem Ausschuss das Gesetz landet, was dann ja auch wiederum Einfluss darauf\nhat, wie die Parlamentsposition aussehen wird.\nAlso wenn es nur im Liebe landet, dann wird die Parlamentsposition relativ hohe\nWahrscheinlichkeit progressiver ausfallen, als wenn es nur im Idre landet,\nwas der Industrie- und Wissenschaftsausschuss ist,\nder traditionell immer recht konservativ, liberal und wirtschaftsfreundlich ist.","Ich habe nochmal eine Nachfrage. Nur mal zu diesem Begriff Hochrisiko.\nRisiko in Bezug auf wen oder was? Also wie ist dieser Begriff gedacht?\nFür wen soll was wie ein Risiko sein, damit das da reinfällt?","Also es ist zum einen der Bereich, in dem es verwendet wird,\nalso zum Beispiel Immigration und zum anderen auch quasi, welchen Impact es\nhaben kann, also welche Einflüsse es quasi auf Menschen haben kann.\nAlso zum Beispiel eben im schulischen Bereich, dass wenn die Systeme quasi nicht\ngut getestet sind oder starken Bias haben oder Cybersecurity-Probleme haben,\ndass sie dann ein höheres Risiko quasi darstellen oder potenziell mehr Schaden\nanrichten könnten als ein Chatbot zum Beispiel.\nWobei ich argumentieren würde, dass auch Chatbots Schäden anrichten können.","Also Risiko im Sinne von Gefährdung für Menschen.","Also ich erinnere mich noch irgendwie, wenn man so Lobbyisten zugehört hat,\nbevor das Gesetz vorgestellt wurde,\nhatten die auch schon diese Idee der Pyramide und die haben halt so plakativ gemeint,\nganz oben ist automatisierte Tötung, wenn die Drohne dich umbringt oder dass\nein Mensch noch irgendwas dafür tun muss und ganz unten ist der Algorithmus,\nder Schrauben sortiert,\nder gar nicht reguliert wird und dazwischen überlegen wir uns dann irgendwas.\nAber das ist halt in der Praxis dann umzusetzen super schwierig,\nweil auch so Dinge, wo sich die Zivilgesellschaft massiv dafür eingesetzt hat,\nwie zum Beispiel das Verbot von Gesichtserkennung, Biometrie oder auch,\nes gibt ja inzwischen so Wahrheitsdetektoren oder Emotionserkennung,\nwo es sehr zweifelhaft ist, ob das technisch überhaupt funktioniert,\nwas da als Produkt angeboten wird.\nUnd da glaube ich, kommen wir dann auch gleich darauf zu, was denn jetzt wirklich\nin diesem Gesetz drinnen steht.\nUnd du hast ja auch schon Migration angesprochen. Wir haben in vielen EU-Ländern\nauch gerade bei arbeitslosen oder arbeitssuchenden Menschen den Einsatz von\nAlgorithmen, wurde teils auch schon von Höchstgerichten verboten.\nAlso da gibt es ja wirklich schon viele Fälle, die nach Regulierung schreien.\nWas wird jetzt besser mit diesem Gesetz?","Vielleicht noch ganz kurz zu Tim, zu der Frage nach dem Risiko.\nAlso zum Beispiel im Artikel zur Definition, da steht unter systemisches Risiko,\ndass ein KI dann ein systemisches Risiko hat, wenn sie einen signifikanten Impact,\nAuswirkungen auf den ganzen Unionsmarkt hat durch ihre Reichweite oder durch\nvernünftigerweise vorhersehbare negative Effekte auf öffentliche Gesundheit, Sicherheit.\nAlso nicht im Sinne von sozusagen innere Sicherheit, sondern Produktsicherheit,\nSafety, nicht Security, Public Security, also öffentliche Sicherheit,\nGrundrechte oder die Gesellschaft als Ganze.\nAber das ist natürlich dann auch eine intellektuelle Herausforderung.\nDamit haben wir auch eine Weile lang gerungen am Anfang, weil dann sagt der\nArtikel 6 zu den Hochrisiko-KI,\ndie Kommission ist ermächtigt, mit einem delegierten Rechtsakt weitere KI-Systeme\noder Anwendungsfälle in den Annex 3 hinzuzufügen, mit den Hochrisiko-KIs,\nwenn diese neuen KI-Systeme oder Anwendungsfälle ein gleich hohes oder höheres Risiko haben,\nals die, die schon im Annex 3 drinstehen. Ja, wie misst man das?\nWie viel ist 1,50 m KI-Risiko? Das kannst du eigentlich nicht schwer vergleichen.\nDas ist immer von Anwendungsdomäne zu Anwendungsdomäne.\nHaben wir echt eine Weile hin und her überlegt und dann am Ende aber gemerkt,\ndas ist eine politische Entscheidung jedes Mal.","Ja, um jetzt auf die Frage zurückzukommen, was ändert sich quasi oder was wird jetzt besser?\nAlso es ist quasi schon so, dass wir natürlich im Vergleich zur Parlamentsposition,\ndie in vielen Fällen besser ist, als das, was dann beim Trilog rauskommt,\nnatürlich nicht alles drin haben, was wir als Parlament angesehen haben als\nproblematisch und zu verbietende KI und als Hochrisiko-KI.\nAlso nur, weil du vorher noch angesprochen hattest, Emotionserkennung,\nMassenüberwachung mit Biometrie,\ndie Polygraphen, das waren alles Punkte, die wir in unserer Parlamentsposition\nkomplett verbannt hätten, also quasi verboten hätten.\nUnd von denen wir nicht alle, aber einige in gewissen Bereichen geschafft haben, zu verbieten.\nDas eine ist eben die Emotionskennung, also quasi die basiert darauf,\ndass man denkt, dass wenn eine Person lacht, dass man davon ableiten kann,\ndass die Person quasi glücklich ist.\nUnd es ist mittlerweile eindeutig bewiesen, dass das nicht funktioniert und\ndass es auch gegen Menschen, die zum Beispiel neuroatypisch sind,\nglaube ich ist das richtige Wort.\nEinfach auch falsch Emotionen erkennt und dass Emotionen einfach sich nicht\nleicht so ableiten lassen.\nDeswegen hat zum Beispiel auch Microsoft Emotionserkennung komplett aus dem\nSortiment sozusagen genommen.\nAlso die entwickeln in dem Bereich auch nicht mehr, weil sie erkannt haben,\ndass es Pseudowissenschaft ist.\nWir haben es zwar nicht ganz durchbekommen, aber wir haben zumindest im Bereich\nam Arbeitsplatz und im schulischen Bereich Emotionserkennung komplett verboten.\nWas ein großer Gewinn für uns vor allem als Grüne war, wo man aber Emotionserkennung\nzum Beispiel noch verwenden darf.\nUnd um ein Beispiel zu nennen, ist eben im Migrationsbereich,\nalso zum Beispiel an Grenzen, was weiterhin hochproblematisch ist,\nweil die Probleme bestehen ja weiterhin.\nEs ist zwar Hochrisiko, aber Hochrisiko heißt halt, du musst einige weitere Regeln erfüllen.\nDas heißt, die KI muss Cybersecurity Standards erfüllen, es müssen gewisse Dokumentationen\ngemacht werden und jetzt in dem spezifischen Fall ist wahrscheinlich auch eine\nGrundrechteabschätzung notwendig, also das sogenannte Fundamental Rights Impact Assessment.\nDas war auch ein großer Gewinn für unsere Fraktion, das mit reinzukriegen.\nDass eben nicht nur der Hersteller, sondern auch der Benutzer,\nalso der, der das System quasi kauft, sondern wirklich anwendet,\nsich auch anschauen muss, was macht die KI eigentlich mit den Personen,\nauf denen ich das anwende.\nDas ist ein bisschen eine Weiterleitung von dem, was schon in den Datenschutzfolgeabschätzungen\ngemacht wird, aber eben speziell auf KI umgemünzt.\nUnd das war für uns insofern ein großer Erfolg, weil das bedeutet,\ndass eben nicht nur der Hersteller, der spezifisch und kontextbasierte Anwendungen\nüberhaupt nicht abschätzen kann, dass sich wirklich der Benutzer hinsetzen muss\nund sich mit der KI auseinandersetzen muss.\nUnd ich glaube, dass es auch eben daraufhin, wie wir KI verstehen und wie wir\ngenerell, wie viel Bedeutung und können wir KI zumessen, sehr wichtig ist.\nWeil wenn das zum Beispiel von Schulen verwendet wird oder auch von Behörden,\ndie vielleicht einen Datenschutzbeauftragten haben und dann das jemandem geben\nund sagen, sagen, ja, verwende das halt, um zum Beispiel Schülern zu helfen,\nin welche Fächer oder in welche Berufe sie sich dann einordnen.\nDass es nicht einfach so angewendet wird, sondern die Personen wirklich wissen,\nokay, welche möglichen Folgen könnte das haben, wenn wir das jetzt mit unseren\nSchülern gemeinsam verwenden.\nUnd ich glaube schon, dass das auch im Laufe der Zeit auch wirklich dazu führen\nwird, dass Menschen einfach besser verstehen, wie KI funktioniert und wo auch\ndie Limits von KI sind, was letztlich auch eine Möglichkeit ist,\nrechtliche Folgen abzuschätzen.\nSo haben wir es auch mal ein bisschen versucht zu verkaufen,\ndas natürlich auch für Unternehmen, das relevant ist, abzuschätzen,\nwo sind die rechtlichen Folgen, die ich möglicherweise habe,\nwenn ich KI verwende, die nicht so gescheit ist, wie ich eigentlich glaube, dass sie ist.","Also eigentlich so wie bei der Datenschutzgrundverordnung, ein neuer Text,\nden ich abnicken muss, wo theoretisch drinnen steht, was mit meinen Daten passiert\noder was da im Hintergrund eigentlich abläuft.\nAlso es muss erklärt werden für die NutzerInnen, was jetzt in diesem System drin ist.","Ja, und der Benutzer muss sich halt auch wirklich damit auseinandersetzen,\nwelche Personen eigentlich mit der KI interagieren oder auf welche Personen\ndie KI angewendet wird und ob das zum Beispiel jetzt Personen mit dunkler Hautfarbe\nsind oder Personen, die eine Disability haben. Genau.\nUnd der Unterschied zur datenschutzrechtlichen Folgenabschätzung ist,\ndass es manchmal Fälle gibt, wo es quasi einen grundrechtlichen Impact haben\nkönnte, wo aber keine persönlichen Daten angewendet werden.\nAlso zum Beispiel, wenn man Migrationsflüsse versucht nachzuvollziehen und daraus\ndie KI irgendwelche Entscheidungen treffen lässt.\nUnd gerade in diesen Bereichen, diese Randbereiche sind, die eben nicht von\nder DSGVO abgedeckt sind, ist das auch besonders wichtig.","Also auch sowas wie Predictive Policing, also dass die Polizei mit Algorithmen\nversucht, vorherzusehen, welche Verbrechen in welcher Region wann passieren,\nwas ja auch ein bisschen so Pseudoscience ist.","Also das vielleicht ganz kurz, Predictive Policing, was sich nur auf bestimmte\nNachbarschaften bezieht oder sowas, das wäre noch erlaubt, würde aber unter\nHochrisiko fallen, müsste also eine Grundrechtefolgenabschätzung machen und alles mögliche.\nAber Predictive Policing über Individuen, dass die KM ja ausrechnet,\nwie wahrscheinlich ist es, dass Thomas Lohninger in den nächsten zwei Monaten\neine Straftat begeht, das ist verboten.\nUnd was wir zum Beispiel auch noch verboten haben, ist das, auf Englisch heißt\ndas Facial Image Scraping, dass ich massenhaft Gesichtsbilder aus dem Internet\nmir zusammenwühle und daraus dann eine große Datenbank mache.\nAlso Clearview AI oder PIM-Eyes ist jetzt verboten.","Und diese Grundrechtsabschätzungen, sind die öffentlich einsehbar?\nKann ich die als User sehen?","Die sind in der Datenbank, oder?","Ich glaube, dass die in der Datenbank gegeben werden müssen.\nEs ist quasi eine neue EU-Datenbank geschaffen worden, wo dann diese Folgerechtsabschätzungen\nhochgeladen werden müssen, um eben mehr Transparenz zu ermöglichen.\nDas war zum Beispiel auch etwas, was nicht im Kommissionsvorschlag drinnen war\nund was uns auch sehr wichtig war, da einfach mehr Transparenz zu schaffen,\nwer das verwendet und ja, auch, dass eben diese Abschätzungen dann öffentlich sind Das war das.","Was die Niederländer schon machen oder Amsterdam oder so. Die haben das schon\nin Betrieb, eine öffentliche Datenbank, wo man sowas genau nachgucken kann.\nDavon haben wir uns inspirieren lassen.","Sowohl die Datenbank als auch die Grundrechtefolgenabschätzung kommen beide\naus den Niederlanden, die Idee.","Es gibt auch unheimlich viele zivilgesellschaftliche Projekte,\ndie einfach so mappen, welche Anwendungen von KI gibt es schon.\nVor allem eben in der öffentlichen Verwaltung, da wo die Leute nicht auskennen,\nwo es kein Produkt ist. ist.\nUnd das heißt, das kommt jetzt europaeinheitlich und diese Datenbank wird dann\nwirklich auch so alles beinhalten oder gibt es da auch wieder Ausnahmen,\ndass zum Beispiel so Polizeimilitären nicht einmelden müssen?","Ganz richtig geraten, Thomas. Natürlich gibt es Ausnahmen und genau eine dieser\nAusnahmen ist, dass KI-Anwendungen im Strafverfolgungsbereich in die Datenbank\nreinkommen, aber in den nicht öffentlich zugänglichen Teil.\nAlso die Aufsichtsbehörden können das weiterhin überprüfen, aber der Öffentlichkeit ist es verborgen.","Was sind denn sozusagen da die Aufsichtsbehörden? Ich habe gelesen,\nda gibt es ein AI-Office.\nIst das das, wovon wir reden?","Es gibt zwei Ebenen oder sogar drei teilweise, weil die Datenschutzbehörden,\nwenn es um personenbezogene Daten geht, auch immer noch eine Rolle haben dabei.\nAber dann gibt es die Marktaufsichtsbehörden, Market Surveillance Authorities,\ndie sozusagen die Standardbehörden sind in diesem ganzen Produktsicherheits-CE-Label-Rahmenwerk.\nUnd dann gibt es aber, da kann Arneka mehr zu sagen, das ist mal diese ganze\nMarktüberwachung, das ist alles Imco-Committee-Territorium, da halte ich mich\nraus, das wissen die viel besser.\nAber es gibt dann eben auch noch das AI-Office in der Kommission.\nDas, warte mal kurz, genau, das ist im Prinzip ein nettes Label für eine neue\nAbteilung in der Kommission.\nAlso in der Definition steht da, das AI-Office means the commission's function\nof contributing to the implementation, monitoring and supervision of AI systems and AI governance.\nDas ist auch schon etabliert. Das wurde durch die Kommissionsentscheidung vom\n24.01.2024 schon eingerichtet.\nDie Kommission kann ja ihre eigene interne Organisationsstruktur selber entscheiden,\nauch wenn das Gesetz noch gar nicht da ist. Aber die fangen jetzt sozusagen\nschon mal langsam an, Leute anzuheuern und das ganze Ding aufzubauen und so.\nZu den Aufgaben steht in dem einen Artikel zum AI-Office eigentlich gar nichts drin.\nDa steht nur, das soll irgendwie das alles irgendwie koordinieren und helfen.\nAber da muss man sich so ein bisschen durch den Text wühlen.\nIn den einzelnen Punkten kommt dann sowas wie zum Beispiel die Entwicklung für\nModellverträge zwischen KI,\nHochrisiko-KI-Anbietern und Drittparteien, die irgendwie Komponenten und andere\nUnterstützungs-Sachen liefern.\nDann, was heißt Template nochmal?","Vorlage.","Eine Vorlage entwickeln für Inklusive eines automatisierten Tools,\ndamit Anbieter von KI ihre Grundrechtefolgeabschätzungen einfacher machen können.\nDann soll sie dabei helfen, dass die Industrie Codes of Practice entwickelt,\nalso Verhaltenskodizes.\nUnd das ist ganz interessant. Das ist immer noch eine Sache der Industrie,\nwie bei vielen anderen Codes of Conduct oder Codes of Practice.\nAber da steht jetzt drin, wenn zwölf Monate nach dem Inkrafttreten des AI Act\ndiese Codes of Practice noch nicht da sind oder die Kommission, also das AI Office,\nfindet, dass die nicht gut genug sind, dann kann die Kommission selber bestimmte\nStandards nochmal verbindlich entscheiden. Ja.\nDann soll das AI-Office die technische Dokumentation von General-Purpose-AI-Modellen,\nalso allgemeinen Zweck, was ist das General-Purpose?","Allzweck-Modellen.","Allzweck-KI-Modellen überprüfen. Dann soll sie eine Vorlage bereitstellen für\neine Zusammenfassung der Inhalte, mit denen die KI trainiert wurde und so weiter und so weiter.\nUnd dann in dem eigentlichen Artikel 64, der dieses AI-Office sozusagen etabliert,\nsteht eigentlich nur, the Commission shall develop union expertise and capabilities\nin the field of AI through the AI-Office. Und das ist eigentlich so der Kern.\nDas war ein Tipp, den wir damals bei einer Anhörung gekriegt haben von Frances\nHaugen, der Facebook-Whistleblowerin, die uns geraten hat, Leute,\nes gibt nicht genug KI-Expertinnen und Experten in der Welt,\num alle 27 Mitgliedstaaten ihre eigenen Expertisezentren aufbauen zu lassen.\nDas müsst ihr europäisch bündeln.\nUnd das war sozusagen die ganze Idee hinter diesem AI-Office,\ndass man sozusagen hier einen Pool von Expertinnen und Experten hat,\ndie dann eben den Mitgliedstaaten auch sozusagen beispringen und die unterstützen\nkönnen bei der Umsetzung.","Klingt jetzt nicht falsch.","Ja, ich wollte nur noch mal sagen, dass das AI-Office auch schon eine Aufsichtsfunktion\nbei den General Purpose AI-Modellen hat.\nUnd das war ein Zusatzbereich, den es im Kommissionsvorschlag nicht gegeben\nhat, nämlich diese Allzweck-Modelle.\nUnd das war ein spezifischer Bereich, wo das Parlament ein komplettes Kapitel\nquasi hinzugefügt hat, weil das Parlament eben gesagt hat, okay,\nes ist so schön, dass wir KI-Systeme regulieren, aber es gibt ja ein Modell,\ndas vor dem KI-System kommt, auf dem das KI-System oft basiert,\nwo quasi die Regeln eigentlich jetzt nicht da sind, vor allem,\nweil das ja alles auf dieses Hochrisiko zugemünzt ist.\nVon grüner Seite, unsere Idee war ursprünglich, dass wir sagen,\nalle Allzweckmodelle sollten alle Hochrisikoanforderungen eigentlich auch erfüllen.\nDas ging aber nicht durch und deswegen haben wir eben einen Kompromiss gefunden,\nverschiedene Anforderungen, die quasi auf den Hochrisikoregelungen basieren,\naber quasi hochrisikoleit auch für diese Allzweckmodelle umzusetzen.\nUnd da hat das KI-Büro jetzt die Funktion.\nZu unterscheiden, welche der Modelle quasi nur die einfachen Dokumentations-\nund Transparenzpflichten erfüllen müssen oder welche Modelle quasi extra Anforderungen\nerfüllen müssen, also quasi in den Top-Tier fallen.\nAlso es gibt zwei Stufen für die Modelle und Modelle, wer zum Beispiel eben GPT-free,\nworauf jetzt Chat-GPT basiert oder ja, also verschiedene Large-Language-Models\nzum Beispiel, aber auch, was auch immer in der Zukunft kommen mag,\nUnd die stärkeren Regeln wären dann zum Beispiel Red Teaming,\nalso interne Risikoanalyse bzw.\nRisikotesten von möglichen Problemen innerhalb des Modells.\nUnd das war eben ein komplett neuer Bereich, den das KI-Gesetz selbst und die\nKommission überhaupt nicht vorhergesehen hatte. Und die jetzt der Kommission\ndeutlich mehr Macht geben, als eigentlich auch vorhergesehen war.\nWeil eigentlich war es wirklich gedacht, dass es national eben über die Market\nSurveillance Authorities und die Data Protection Authorities in jedem Mitgliedstaat\neinzeln die KI-Systeme überwacht werden.\nUnd jetzt sind die ganzen Modelle ausgelagert zu dem AI-Office,\ndas eben nicht nur eben die ganzen Punkte erfüllen kann, die Ralf vorhin schon\nerwähnt hat, sondern eben auch einteilen kann,\nwer das quasi Modell leiht und wer das Modell, das quasi einen höheren Impact\nhat und deswegen weitere Anforderungen erfüllen muss.\nUnd das ist auch insofern interessant, weil in der Zukunft das AI-Office auch\nweitere problematische oder impactful Modelle hinzufügen kann in den Top Tier\nund deswegen ja relativ viel Macht bekommt.","Und wir wissen seit heute Morgen schon, wer der Chef wird.","Bevor wir dazu kommen, die generelle Struktur davon, dass wir das mal wiederholen.\nAlso an sich war gedacht, die ganze Rechtsdurchsetzung über diese nationalen\nMarktaufsichtsbehörden zu machen.\nUnd jetzt ist sozusagen auf Bestreben des Parlaments hin,\ndieses AI-Office bei der Kommission mächtiger geworden in Bezug auf das Einstufen\nvon konkreten KI-Systemen gemäß ihrem Risikogehalt.\nHalt dieser generellen Modelle, General Purpose Modelle, da kann man sich wahrscheinlich\nso die klassischen Large Language Models vorstellen, oder? Ja?\nUnique. Und du hast dann aber am Ende eigentlich so welche Auflagen,\nweil für mich ist so, das habe ich auch mit Kolleginnen schon diskutiert aus\nder Zivilgesellschaft,\nes ist so ein bisschen sehr weird, jetzt zu sehen, dass eine Marktaufsicht auf\neinmal Grundrechte einhalten soll.\nAlso wo sind wir denn jetzt mal so ein Testcase von, ich weiß nicht,\nClearview AI haben wir vorher gesagt, das ist sowieso ganz verboten,\naber was gibt es denn so für Beispiele, die ihr nennen könnt,\nwo nach eurer Lesart des Gesetzes einem Unternehmen auch Konsequenzen drohen,\nwenn durch die eigenen Systeme wirklich Schaden auftritt bei Menschen.\nIst das alles nur eine theoretische Sache, wo ich eine Abschätzung irgendwo hinterlegen muss?\nOder kann ich da zum Beispiel auch als Betroffener klagen? Wir haben ja,\nglaube ich, auch in der Sendung zuletzt schon diesen British Post Office Scandal diskutiert,\nwo aufgrund eines Fehlers eines Computersystems hunderte Menschen fälschlicherweise\nderen Existenzen zerstört wurden.\nJa, hätte man vielleicht im Vorhinein auch nicht gesagt, dass es ein Hochrisikosystem sein soll.\nWar es dann aber am Ende? Also würde der AI-Act bei solchen Fällen helfen und wenn ja, wie?","Also zum einen zur AI-Liability, also quasi zu dem Schwestergesetz zur Produkthaftungsrichtlinie.\nDa warten wir ja immer noch darauf, dass es da in dem Bereich eine Entscheidung geben wird.\nUnd das würde, glaube ich, vieles von den Fällen, die du gerade genannt hast,\nalso wie kann ich persönlich vorgehen und persönlichen Schaden,\nWas es schon gibt, ist, dass das KI-Gesetz auch die Möglichkeit hat,\nüber die Collective Redress, also kollektive Verbandsklage, dass Verbandsklagen\nquasi ermöglicht werden.\nDas heißt, wenn du quasi nachweisen kannst, dass der Hersteller zum Beispiel\ndie Anforderungen nicht erfüllt\nhat im Hochrisikobereich, dann wäre zum Beispiel so eine Klage möglich.\nWir haben auch eingeführt, dass eine individuelle Person auch zu einer nationalen\nBehörde gehen kann und sich beschweren kann, wenn man glaubt,\ndass innerhalb dieser Regulierung gewisse Pflichten nicht erfüllt worden sind.","Aber ich hake genau da ein. Also wenn ich jetzt ein Unternehmer bin mit einer\nganz bösen Absicht, so ein typischer Überwachungsschweinekonzept,\nkann ich sozusagen hier meinen Kopf aus der Schlinge ziehen,\nwenn ich genügend Papier produziere und über alle diese Risiken ganz viele Abschätzungen mache?\nOder ist am Ende der real auftretende Schaden das, was auch zu der Strafe führen kann?\nEgal wie viel Papier ich da vielleicht rundherum mir zugekauft habe,\num das zu kaschen, um das irgendwie so einzukleiden.","Ja, wenn du es als böser Überwachungskapitalist mit einer fiesen Firma es schaffst,\nirgendwie alle Auflagen des AI-Acts zu erfüllen, inklusive Grundrechte, Folgenabschätzung,\ninklusive die Auflagen zu Data Governance, dass du zum Beispiel gucken musst,\nob in deinen Trainingsdaten irgendwelche Biases versteckt sind und wenn ja,\nmusst du das irgendwie angehen und so. Wenn du das alles schaffst, dann bist du raus.\nJa, ich möchte nur den fiesen Überwachungskapitalisten sehen, der das hinkriegt.\nAber grundsätzlich, ich glaube, die Logik ist sozusagen, wenn ein konkreter\nSchaden entsteht, dann greift sowieso die Produkthaftungsrichtlinie jetzt,\nweil die jetzt ja auch für alle digitalen Produkte gilt.\nWobei, nee, warte, die greift ja nur, wenn ich mir das Produkt selber gekauft habe. Stimmt.\nNicht, wenn ich Opfer von einem Produkt von jemand anderem bin.\nAber der AI-Act, soweit ich es im Kopf habe, aber correct me if I'm wrong, Annika,\nder sieht Strafen und Ähnliches dann vor, wenn die Anbieter von KI-Systemen\noder auch die Nutzer von KI-Systemen gegen Regeln des AI-Acts verstoßen.\nUnabhängig davon, ob am Ende ein Schaden rauskommt oder nicht.\nSchaden kann dann immer auch noch zivilrechtlich und anders wie irgendwie eingeklagt werden.","Aber da will ich jetzt nochmal einhaken, weil ich fand das Beispiel,\nwas Thomas genannt hat, mit diesem Post-Office-Skandal eigentlich ganz plastisch,\nweil das ja eine, also da ist der negative Impact ja sehr offensichtlich,\nja, also da sind ja, Leute haben sich ja umgebracht deswegen,\nweil eine Software falsch gerechnet hat und wie du schon sagst,\ngekauft haben sie aber das Produkt nicht, sondern sie mussten das sozusagen\nim Rahmen ihrer vertraglichen Bindung mit dem Post Office,\nUK Post Office sozusagen benutzen oder es wurde für sie benutzt und es war eigentlich\ndie Software der Post sozusagen.\nAlso ist irgendetwas in diesem AI-Eck, wo ihr sagen würdet, hier greift jetzt\ndiese Idee der Entscheidungsfindung und der Macht der Algorithmen,\ndie diesen Fall abgedeckt hätte?","Also ich glaube, es geht eher darum, dass die Produkte, die zukünftig auf den\nMarkt gebracht werden, gewisse Standards erfüllen müssen.\nDas heißt, die Wahrscheinlichkeit, dass so ein schädliches oder ein schadhaftes\nProdukt auf den Markt gebracht wird, versucht der AI zu minimieren,\nindem er eben Data Governance, Cyber Security und so weiter vorschlägt.\nUnd alles, was dann quasi später passiert, findet eben in der AI Liability Directive,\ndie es noch nicht gibt, also KI-Haftungsrichtlinie statt.\nUnd der Hayek versucht quasi nur sicherzustellen, dass die Produkte,\ndie in Zukunft in der EU auf den Markt kommen,\nein Minimum an Standards erfüllen, die wir quasi in unseren EU-Values als wichtig\ngenug ansehen, damit KI auch trustworthy wird,\nalso vertrauensbindend, also dass man quasi ein gewisses Vertrauen in die KI hat.","Ja gut, aber hier ist es ja noch nicht mal KI. Hier ist ja Plus und Minus nicht\nrichtig benutzt worden.","Dann würde es eigentlich nicht in den Scope vom KI-Gesetz kommen.","Das heißt, das ist sozusagen immer noch nicht sanktioniert.\nJa, nee, verrechnen dürft ihr euch, aber ihr dürft nicht im abstrakten Raum\nfalsch sein, nur im konkreten. Ist auch ein bisschen doof, oder?","Ja, aber dass die sich da einfach stumpf verrechnet haben, das wird ja wohl\nirgendwelche rechtlichen Folgen haben müssen, oder?","Ja gut, also ich meine, das geht jetzt schon seit über zehn Jahren ist es bekannt,\ndass sie sich verrechnet haben und es ist ja jetzt erst durch eine Fernsehserie\nim englischen Fernsehen und britischen Fernsehen überhaupt erst zu einem Skandal geworden,\nweil dann die Öffentlichkeit gesagt hat, was geht denn hier ab und in der Zwischenzeit,\nwie gesagt, Leute hat das halt in den finanziellen Ruin getrieben und mehrere\nder Betroffenen haben sich halt einfach das Leben genommen.\nUnd das ist halt schon irgendwie so ein Level, wo ich sagen würde,\nda kann man schon mal rein regulieren, um sicherzustellen, dass so etwas nicht geht.\nDeswegen frage ich halt einfach ganz blöd, seht ihr jetzt irgendwas in diesem\nAI-Act oder in dieser Product-Liability-Richtlinie, das so etwas verhindert\noder ist das jetzt tatsächlich noch nicht mal abgedeckt?","Wenn es um einfaches Plus-Minus geht, ist es nicht abgedeckt.\nDas ist ja nicht unter KI.","Also verrechnen darf man sich nach wie vor, nur nicht falsch schwurbeln.","Also es gab auch im KI-Gesetz ganz stark den Push, es nur auf Machine Learning\nzu begrenzen, also KI nur als Machine Learning zu begreifen.\nUnd es hat uns sehr viel Kraft gekostet, dass zumindest Teile von Automated\nDecision Making weiterhin im Skop von KI-Gesetz drin sind. Also so einfachere\nSoftware ist im KI-Gesetz auf jeden Fall nicht mit ihm begriffen.","Ja gut, aber ich meine, in dem Fall war es ja so,\ndass den Vertragspartnern des Post Office quasi ein Fehler nachgewiesen wurde,\nden es so nie gegeben hat und das ist ja eigentlich auch eine Entscheidungsfindung.\nEs war nämlich die Entscheidungsfindung mit, deine Abrechnung stimmt nicht, obwohl sie stimmt.\nSo und damit ist ja sozusagen von einer Software eine falsche Entscheidung gefällt\nworden, die dann auch später niemand anzuzweifeln bereit war,\ngeschweige denn irgendeine Verantwortung dafür zu übernehmen.\nUnd alle haben sich gegenseitig da in Schwarzenpeter zugezogen und alle, die das halt,\nes wurde ja noch dadurch verschlimmert, dass halt das Post Office auch noch\nin UK, gut ich weiß jetzt nicht EU und so, aber es geht ja jetzt nur sozusagen\num so einen Fall, der ja durchaus realistisch ist, weil der hat ja stattgefunden,\ndass das Post Office halt auch noch so einen anderen rechtlichen Status hat und so weiter.\nAlso es war also generell sehr schwierig, da überhaupt irgendwie gegenzugehen\nund es hat die Leute halt einfach mal komplett ruiniert.\nDas ist ja schon ein ziemlich harter Tobak. Also in meiner Wahrnehmung ist auch\neine Berechnung, eine Saldos, eine automatische Entscheidungsfindung,\nweil ja da am Ende eine Wahrheit geliefert wird.\nNämlich die Wahrheit mit, du hast uns genug Geld gegeben oder du hast uns nicht genug Geld gegeben.","Ich verstehe dein Reasoning und es ist nicht so, dass ich dir widerspreche.\nIch kann dir aber sagen, dass genau diese einfacheren Entscheidungsfindungen,\ngenau das ist, was der Großteil der Personen, die am Verhandlungstisch saßen,\nvor allem die Kommission und der Rat, auf gar keinen Fall drin haben wollten.\nAlso da ging es schon darum zu sagen, es muss etwas sein, was schon auf höheren\nEbenen quasi arbeitet und jetzt nicht ganz einfache Rechnungen und Excel-Tabellen.\nIn Excel-Tabellen war immer so ein Beispiel, was sie gebracht haben.","Die müssen auch weiterhin falsch sein dürfen, sonst läuft gar nichts mehr.","Ich würde da gerne noch einen zweiten Fall reinnehmen, und zwar dieser niederländische\nSkandal, wo die Steuerbehörden sich vertan haben, wo ja auch die Regierung von\nMark Rutte darüber gestolpert ist.\nUnd das als Frage zu formulieren,\nes macht für den AI keinen Unterschied, ob jetzt ein Unternehmen hier dieses\nProdukt auf den Markt bringt und diesen Fehler macht oder diesen Bias hat oder\nob es die öffentliche Hand ist, wo man ja vielleicht sagen könnte,\nda wollen wir höhere Anforderungen haben.\nWeil beim Unternehmen kann ich vielleicht noch irgendwie sagen,\nokay, gut, da werde ich kein Kunde.\nAber wenn es jetzt irgendwelche Behörden sind, die solche algorithmischen Systeme\nanwenden, habe ich oft keine Wahl.\nGibt es da höhere Auflagen für die öffentliche Hand?","Also es gibt grundsätzlich, die Hauptlast der Anforderungen liegt auf jeden\nFall beim Hersteller und nicht beim Anwender.\nAlso das ist mal so die grundsätzliche Idee auch vom KI-Gesetz.\nDas heißt, wenn, dann würde wahrscheinlich, also gerade wenn die KI in irgendeiner\nForm fehlerhaft, also zum Beispiel eben Bias hat, dann würde das eher auf den\nHersteller fahren als auf den Benutzer.\nWas es aber eben schon gibt und das ist eben vor allem für Behörden,\nwird es wichtig sein, ist eben diese Grundrechtefolgenabschätzung,\ndie vielleicht in dem Fall, den du genannt hast, gegriffen hätte,\nweil sie sich dann schon bewusst gewesen wären.\nDas geht aber dann schon gegen Personen, die dann zum Beispiel sozial benachteiligt\nsind. Aber die Hauptklasse wäre eigentlich bei dem Hersteller.\nUnd es gibt in dem Sinne ein paar zusätzliche Anforderungen für Behörden.\nAber trotzdem muss eigentlich der Hersteller garantieren und sicherstellen,\ndass die KI in Ordnung ist.","Aber wenn ich das ergänzen kann, dieser holländische Sozialversicherungsfall,\nder hat uns natürlich hier alle bewegt.\nUnd eine unserer Co-Verhandlerinnen war ja die grüne Abgeordnete aus Holland,\nKim van Starrentaak im Innenmarktausschuss, neben Sergej Labudinski im Innenausschuss.\nUnd da ist jetzt im Annex 3 für die Hochrisiko-KIs Punkt 5 drin,\nextra, der war auch schon vorher von der Kommission, den haben wir nur ein bisschen\naufgebohrt, alles, wo eine KI eingesetzt wird zum Entscheiden,\nob jemand Zugang zu essentiellen privaten Diensten oder essentiellen öffentlichen\nDiensten und Benefits, also...","Also staatliche Leistungen, Sozialhilfe.","Oder auch essentielle private Leistungen, wenn das irgendwie Versicherungsleistungen\nsind oder sowas, keine Ahnung.\nDann fällt das auf jeden Fall unter Hochrisiko-KI, man muss die ganzen zusätzlichen Auflagen erfüllen.\nUnter anderem, wenn es um Gesundheitsdienste geht, aber auch darum zu entscheiden,\nob jemand Anspruch auf irgendwelche Leistungen hat.\nOb es Renten sind, Sozialversicherungsansprüche, was auch immer.\nOder wenn man in dem Kontext versucht, die Kreditwürdigkeit von Leuten abzuschätzen mittels KI.\nDas ist auf jeden Fall auch Hochrisiko und braucht dann eben die ganzen Dokumentationspflichten,\nBias, es muss angegangen werden in Trainingsdaten und, und, und.","Das heißt, um es pragmatisch zu machen, wenn ich meine Haushaltsversicherung\nmir verwehrt wird oder das Jobcenter sagt,\ndu kriegst deine Arbeitslose jetzt nicht mehr oder die Schulung nicht mehr bezahlt,\ndann wäre das Hochrisiko, auch wenn das vielleicht nur mit Excel passiert.","Nee, nur wenn es auf Basis von einer KI passiert.\nAlso wenn es schon irgendwie ein Machine Learning System dahinter hängen.\nWas aber immer ergreift, unabhängig vom AI Act, ist dann der Artikel in der\nDSGVO zu Profiling und automatisierter Entscheidungsfindung,\nwo ja eh schon drin steht,\nman darf als natürliche Person nicht sozusagen Opfer sein von einer negativen\nEntscheidung, die ausschließlich mit automatisierten Entscheidungssystemen getroffen wurde.\nAlso da ist auch immer noch ein Mensch verantwortlich. Und ich habe immer noch\ndas Recht, mich da auch zu beschweren entsprechend nach DSGVO und so.","Ja, ich denke, es wird dann nicht so lange dauern, bis die AI auch in Excel das Sagen hat.\nVon daher fällt es dann vielleicht irgendwann doch wieder da drunter.\nNa gut, also ein paar Lücken bestehen auf jeden Fall noch.","Ja, wenn du gerade Lücken ansprichst, kann ich noch eine Lücke nennen,\ndie wir leider im Endgesetz jetzt drinnen haben.\nAlso ich habe schon vorhin erwähnt, dass quasi das ganze Gesetz das Wichtigste\nist eigentlich, okay, jetzt neben den General Purpose AI Punkten,\ndie gut sind, die Hochrisikofälle und die Hochrisiko-KI.\nUnd da gibt es einen Artikel, der quasi sagt, was fällt in Hochrisiko und was\nnicht. Das ist der Artikel 6.\nUnd das war eigentlich die Krux in dem Ganzen oder das Wichtigste in dem ganzen\nGesetz, nämlich was fällt also aus dem Annex, den wir dazu haben,\nquasi die Bereiche drinstehen, tatsächlich in alle Anforderungen quasi, die im Gesetz stehen.\nUnd da gibt es jetzt quasi drei Möglichkeiten, wie man sich aus dem Gesetz wieder\nrausholen kann, die relativ weit formuliert sind und möglicherweise auch noch\nin Zukunft zu Problemen führen könnten, weil sie so weit formuliert sind.\nDas heißt, man kann sich dann eigentlich wieder aus den Hochrisikoverpflichtungen\nrausholen, wenn man in diese drei Bereiche fällt.\nDie ganze Raison des Gesetzes, auf dem die Kommission auch ihre Logik aufgebaut\nhat, ist eigentlich mit diesem Artikel 6 und mit diesen Ausnahmen ein bisschen zerstört worden.\nUnd das ist etwas, das für uns sehr hart hinzunehmen.","Was sind das für Ausnahmen?","Ein ganz kleiner Moment. Also, wenn die KI nur narrow procedural,\nalso prozedurale Anwendungen sind, die quasi so ein bisschen nebenbei laufen,\naber nicht quasi das Hauptressort der KI sind, dann kann man sich rausnehmen,\nwas jetzt genau diese narrow procedural tasks sind.\nHaben wir jetzt ein bisschen im Erwägungsgrund erklärt, könnte man aber auch\nrelativ weit begreifen.\nDann sagt es, wenn die KI nur versucht, eine bereits ausgeführte menschliche\nAktivität zu verbessern, was ist eine bereits ausgeführte menschliche Aktivität?\nDas könnte alles sein. Ich glaube, Ralf hat gesagt oder jemand,\nes könnte eine gebaute Pyramide sein.\nDas ist ja auch eine beendete menschliche Aktivität. Also, ja,\nproblematisch, wenn das KI-System nur Decision-Making-Patterns versucht zu verbessern\nund keine menschliche Entscheidung entwickelt.\nErsetzt.","Aber das ist ja genauso wie das, was Ralfrat gesagt hat.\nBei der DSGVO haben wir auch diesen guten Artikel, die automatisierten Entscheidungen,\ndie sozusagen zustimmungspflichtig ist, wenn sie ausschließlich von einer Maschine getroffen wird.\nAlso solange da irgendwo noch ein Mensch sitzt, der die ganze Zeit nur auf OK\nklickt zu dem, was die Maschine ihm vorgibt, kannst du dich eigentlich wieder rausreden.","Ja, was höchst problematisch ist und was eben auch zum Beispiel dieser Human\nOversight Artikel, also eine dieser Regeln, die die Hochrisiko-KI zu befolgen\nhaben, ist eben, dass es einen Human in the Loop gibt, also einen Menschen,\nder da sitzt und eben okay drückt.\nUnd wir haben quasi auch versucht, bei den Verhandlungen zu erklären,\ndass es sowas wie Automation Bias gibt, also dass man quasi davon ausgeht,\ndass wenn die KI sagt, naja, die Person ist in irgendeiner Form kriminell,\ndann wird das schon stimmen, weil die hat das ja aufgrund von irgendwelchen Parametern bemessen.\nUnd das ist eben genau das Problem, dass nur weil ein Mensch da sitzt und das\nüberprüft, das nicht immer mit einem großen Gedankengang einhergeht,\nweil die Personen oft gar keine Zeit haben, sich da groß zu überlegen,\nwelche Parameter da jetzt in die KI angeflossen sind.\nUnd das ist natürlich schon problematisch, dass es jetzt diese Möglichkeiten\ngibt, um sich quasi wieder aus dem AI rauszuholen.\nDas gilt aber nur für KI-Systeme und nicht für die Modelle. Also für die Modelle\ngibt es diesen Filter, in Artikel 6 für die gilt er nicht.","Was wir in der Parlamentsposition, wenn ich mich richtig erinnere,\ndritte hatten, war ein ausdrückliches Verbot dafür, dass eine KI quasi Urteile\nschreiben darf, die der Richter am Ende nur noch unterzeichnet.\nDas ist aber leider im Trilog wieder rausgeflogen.","Da würde ich gerne wissen, welcher Mitgliedstaat sich dafür eingesetzt hat,\ndass das künftig gehen kann.","Keine Ahnung.","Ja, wir haben da zu viel...","Wir haben mit den Spaniern verhandelt vor allem. Aber wer dann dahinter steckt,\nist uns immer so ein bisschen unklar, wenn man da nicht die Kontakte hat.\nUnd natürlich eine Sache vielleicht noch zum Schluss.\nDas riesengroße Ding, das bis zum Schluss umstritten war und uns da irgendwie\nzwei Nächte noch gekostet hat, war halt die Frage mit Gesichtserkennung im öffentlichen Raum.","Ja, ich wusste, dass das jetzt so kommt. Ich hätte dich sonst gleich danach\ngefragt. Wie ist das denn gelöst?\nHier war die große Forderung der Zivilgesellschaft, Gesichtserkennung im öffentlichen\nRaum wirklich gänzlich als Hochrisikotechnik zu verbieten und daran anschließend\nnatürlich auch alle anderen Formen biometrischer Erkennung am Gang,\neinfach alles, wo uns Bewegungsfreiheit im öffentlichen Raum weggenommen wird\nund Datenschutz eingeschränkt.\nDas war auch mit einer europäischen Bürgerinitiative nochmal bestärkt,\ndiese Forderung, Reclaim Your Face, hieß die Kampagne.\nUnd das hat es ja, glaube ich, auch in die Parlamentsposition geschafft.\nNehmt uns nicht die Hoffnung. Was ist daraus geworden?","Das übernehme ich mal, ja. Das ist eher mein Blutfallbereich.\nJa, es steht jetzt in Artikel 5, Paragraph 1.h.\nAlso Paragraph 1 ist, die folgenden KI-Praktiken sind verboten.\nParagraph h, die Nutzung von Echtzeit-biometrischen Identifikationssystemen\nauf Entfernung in öffentlich zugänglichen Räumen für die Zwecke der Strafverfolgung.\nIst verboten, steht so drin, aber leider ist der Satz dann noch nicht zu Ende.\nDer geht nämlich dann weiter, außer und insoweit, als solche Benutzung strikt\nnotwendig ist für eines der folgenden Zwecke.\nUnd dann kommen sozusagen die Ausnahmen, wo es dann doch erlaubt ist,\ndie gezielte Suche nach spezifischen Opfern von Entführung oder Human Trafficking oder so.\nZweitens die Verhinderung einer spezifischen,\nsubstanziellen und unmittelbar bevorstehenden Bedrohung für das Leben oder die\nphysische Sicherheit von natürlichen Personen oder einer genuinen und gegenwärtigen\noder vorhersehbaren Bedrohung einer terroristischen Attacke.\nUnd drittens die Identifizierung und Lokalisierung von einer Person,\ndie verdächtig ist, eine Straftat begangen zu haben, die mit einer Höchststrafe\nvon mindestens vier Jahren Gefängnis bestraft werden kann.\nAlso für die Zwecke wäre es noch erlaubt. Also die Idee war sozusagen dahinter\ndann am allerletzten Kompromiss, Donnerstag, Freitagnacht oder wann,\nkurz vor Weihnachten, dass wenn irgendwo jemand eine Tankstelle ausgeraubt hat\nund davonrennt oder davonfährt auf dem Motorrad oder so und vielleicht keinen\nHelm auf hat, dass man dann schnell in Echtzeit die Kameras,\ndie es da in der Gegend gibt,\nwenn die sozusagen verbunden sind und Gesichtserkennung überhaupt können und\nsowas, einschaltet und sagt, hier, den finden wir mal diesen einen Räuber hier.\nDamit wir, solange der noch in der Nachbarschaft ist, irgendwie grob eine Chance\nhaben, dass der irgendwie noch gefasst wird.\nDas war sozusagen die Idee. Da kann man dann sagen, ja, ist total offen und\nweit. Das hat aber bestimmte weitere Voraussetzungen noch.\nDas soll autorisiert werden von einer Justizbehörde oder einer anderen Behörde,\ndie binnen der Entscheidungen treffen können, also de facto Staatsanwaltschaft\ndann wird das sein in der Praxis.","Ein Richter?","Ja, eben, Justiz oder Staatsanwaltschaft. Dann muss diese Behörde,\ndie es anwenden will, vorher eine Grundrechtefolgenabschätzung gemacht haben mit dem System.\nZumindest in der Regel, es gibt Ausnahmen. Dann muss es strikt limitiert sein in Bezug auf die Zeit,\nin der das gemacht werden darf,\nalso die Dauer und den geografischen und persönlichen Anwendungsbereich.\nDu kannst ja nur die Nachbarschaft überwachen, aber nicht ganz Berlin oder so oder ganz Brüssel.\nUnd jede Nutzung soll den zuständigen\nMarktaufsichtsbehörden und Datenschutzbehörden notifiziert werden.\nUnd das Ganze ist aber sozusagen nur die Leitplanke. So weit darfst du maximal gehen.\nDas ist noch keine Rechtsgrundlage dafür. Es steht dann in § 5,\num das machen zu können, müssen die Mitgliedstaaten selber noch eine Rechtsgrundlage\nin ihrem nationalen Recht schaffen.\nAlso wir haben als KI-Gesetzgeber hier jetzt nichts erlaubt.\nWir haben nur gesagt, wenn ihr das macht, müsst ihr diese Leitplanken einhalten.\nUnd es steht ausdrücklich drin, die Mitgliedstaaten können auch restriktivere\nGesetze verabschieden zu dem Thema.","Da ist aber jetzt ein Wort drin, nämlich das Wort Echtzeit.\nWenn ich das jetzt richtig verstanden habe, schließt diese ganze Regelung nur\ndie Echtzeitverwendung aus, aber nicht die Vorratsdatenspeicherung sozusagen.","Die Vorratsdatenspeicherung von Kamerabildern ist nochmal ein ganz anderes Thema.\nDas ist nicht vom KI-Gesetz geregelt. Also wie lange so eine Kamera Bilder aufbewahren\ndarf, das ist außerhalb des Geltungsbereichs vom AI-Act.","Ja, beziehungsweise wenn man halt jetzt sozusagen Gesichtserkennung macht auf\nden Daten, aber halt nicht in Echtzeit.","Du speicherst die fünf Minuten ab und danach machst du die Gesichtserkennung drüber.","Zum Beispiel, oder auch ein paar Tage so.","Oder es ist halt irgendwie, du hast es vorher gesagt, nur für den strafrechtlichen\nBereich. Die Privaten sind davon jetzt nicht umfasst.","Die Privaten sind nicht erfasst und auch sowas wie Grenzkontrollübergänge sind nicht erfasst.\nDas ist von der Datenschutzgrundverordnung geregelt. Da gibt es zum Beispiel\nauch schon Entscheidungen der Datenschutzbehörden, wenn irgendwelche Fußballstadien\nein Verbot hatten von Hooligans, dann haben sie teilweise Gesichtserkennung\neingesetzt, um die einzelnen Hooligans, die ein Stadionverbot hatten, zu finden.\nDa gibt es Entscheidungen der Datenschutzbehörden, sozusagen außerhalb dieser\nRegelung hier. Was es aber auch noch gibt, ist eine Regelung zu retrograder\nbiometrischer Gesichtserkennung, also Post-RBI, eben nicht in Echtzeit.\nUnd da ist eben die Idee, dass das nicht mehr verboten ist, sondern nur noch\nHochrisiko, was für uns ein super, super dicke Kröte war, das zu schlucken.\nKönnt ihr euch vorstellen.\nWir wollten komplett verabredet von allem. Wir haben jetzt schon in Echtzeit\nda irgendwie ein paar Ausnahmen drin reingekriegt, die aber,\nwie gesagt, für spezifische Verdächtige und so nur greifen.\nUnd für retrograde KI-Echtzeit, nein, für retrograde Gesichtserkennung im öffentlichen\nRaum, da brauchst du erstmal die Aufnahmen, sonst kannst du es nicht machen.\nUnd da gibt es dann eben unter Datenschutzrecht schon Regeln,\nwie lange dürfen Videokameras die Daten speichern und so und nach wie vielen\nStunden müssen sie gelöscht werden oder überschrieben werden.\nUnd wenn du diese Daten noch hast, wenn die mal gespeichert sind und auch legal\nnoch gespeichert waren, dann kannst du die jetzt für ähnliche Fälle benutzen,\nnämlich für eine gezielte Suche nach einer Person,\ndie auch wieder einer Straftat verdächtig ist, in dem Fall nicht mal eine schwere\nStraftat, sondern generelle Straftaten, wiederum mit Autorisierung eines Gerichts\noder einer Staatsanwaltschaft.\nLimitiert auf das, was strikt notwendig ist für die Ermittlung in einem spezifischen\nStrafverfahren, also kannst du die einfach allgemein erstmal alle so abscannen, ohne Anlass,\nIn keinem Fall soll so ein Hochrisiko-KI-System genutzt werden für Strafverfolgungszwecke\nin einer ungezielten Art,\nuntargeted way, ohne Link zu einer spezifischen Straftat oder einem Strafverfahren\noder eben einer spezifischen drohenden Gefahr oder so.\nUnd solche Nutzungen müssen dann zumindest in der relevanten Polizeiakte dokumentiert\nwerden und auch den Marktaufsichtsbehörden und Datenschutzbehörden verfügbar\ngemacht werden auf Nachfrage.\nUnd wir sind uns, glaube ich, alle echt einig, dass das nicht gut ist.\nDas ist irgendwie viel, viel offener und viel weiter, als wir es uns gewünscht hätten.\nDas war am Ende sozusagen der Kompromiss, der auch noch total verfahrensmäßig\nrichtig übel gelaufen ist. Wir hatten am letzten Abend des Trilogs, das war das 12., 10.\nDezember oder so, hatten wir noch keinen finalen Text zu dieser retrograden Gesichtserkennung.\nWir hatten aber vorher einen Text von einer spanischen Ratspräsidentschaft bekommen,\nder irgendwie in die richtige Richtung ging. ging.\nDa war noch eine limitierte Liste mit Straftaten, wo das genutzt werden kann und so weiter.\nAber irgendwie ist es dann nicht mehr dazu gekommen, noch einen finalen Text\nauszufaden in der Nacht.\nUnd dann sind alle nach Hause und ins Wochenende und am Montag oder Dienstag\nhaben wir noch mal wieder ein paar Aufräumtermine gehabt auf technischer Ebene,\nalso Mitarbeiterebene.\nUnd dann kriegen wir plötzlich von den Spaniern da einen Text präsentiert,\nder einfach komplett anders war als das, was wir gedacht hatten, wie die Einigung ist.\nUnd dann ging es wirklich noch zwei Wochen hin und her.\nDie letzte Woche war dann irgendwie die die Sitzungsfeierwoche vor Weihnachten,\nwo alle schon im Urlaub waren.\nIch saß da irgendwie an der Nordsee im Ferienhaus und habe mir noch E-Mails hin und her geschickt.\nUnd dann ist am Ende das hier rausgekommen, wo dann auch irgendwie jetzt sozusagen\nkeiner mehr das Fass nochmal komplett aufmachen wollte.\nDer Trilog war sozusagen schon fertig und dann wurde diese Kröte geschluckt.\nMuss man nicht gut finden, überhaupt nicht. Und die Bundesregierung hat,\nglaube ich, schon entschieden, dass sie es auf jeden Fall enger ziehen will,\nwenn es überhaupt in Deutschland irgendwie Gesetzesgrundlage dafür geben wird.\nUnd wir werden natürlich weiter dafür kämpfen, wenn das Ding mal wieder renoviert\nwird oder andere Gesetzesvorschläge kommen, die das irgendwie berühren könnten,\ndass das auf jeden Fall enger gezogen wird, ganz klar.\nAber an dem Punkt jetzt den ganzen AI-Act scheitern zu lassen,\nwar es uns auch nicht wert genug, weil da einfach so viele Sachen drin sind,\ndie einfach jetzt mal gut sind, dass sie an den Start kommen.","Es war ja kurzzeitig so, dass es die Mehrheit im Rat in der Schwebe stand und\nwir beide haben uns ja genau zu der Zeit getroffen und du meintest,\nob ich da irgendwie bei der österreichischen Justizministerin fragen würde.\nIch bin mir bis heute nicht sicher, ob das Gesetzeswert wäre, gerettet zu werden.\nAber um vielleicht auch da zum Abschluss zu kommen, würde mich von euch beiden\nnoch interessieren, was mit diesem Gesetz denn jetzt wirklich so die prägnante\nSache, der prägnante Missstand sein soll,\nden wir damit wirklich hoffentlich verbessern.\nBei der DSGVO, was ja damals Facebook, da war die große Erwartungshaltung,\ndass wir damit endlich Facebook dazu bringen, mit personenbezogenen Daten besser umzugehen.\nIch glaube, es ist sehr überschaubar, was wir damit wirklich geschafft haben,\ntrotz aller guten Absichtsbekundungen damals. Wie ist es beim AI-Act?\nAlso ist da jetzt Palantir zum Beispiel, müsste es da eigentlich Änderungen\nin der Realität geben mit diesem Gesetz, wo ihr sagt, da sollte wirklich sich\netwas in der Praxis ändern oder auch die Schufa zum Beispiel.\nAlso Kreditauskunft Hain ist da aus eurer Sicht, um es nochmal zu Ende ganz praktisch zu machen.\nWas erwartet ihr euch jetzt von dem AI-Act, an dem ihr so lange gearbeitet habt?","Ich fange mal an. Also ich glaube, dass so ein bisschen das,\nwas quasi immer unter diesem Begriff vertrauenswürdige KI,\nmade in Europe, quasi gedacht wird, dem quasi ein bisschen ein Gesetz dahinter\ngelegt wird, was das eigentlich bedeutet.\nDas heißt, welche konkreten Anforderungen haben wir an die zukünftigen KI-Systeme,\ndie in Europa auf den Markt gebracht werden?\nWas sind sozusagen die Mindestanforderungen, die das erfüllen muss?\nUnd das Gleiche für die Modelle. Also es ist quasi eine Mindestanforderung,\nein bisschen eine Ausdeklinierung dessen, was wir quasi unter schönen Worten\ndie ganze Zeit erzählen, wie wir das gerne hätten.\nUnd ein paar Systeme sind eben komplett verboten, aber es sind eben viel weniger,\nals wir eigentlich für notwendig gehalten hätten.\nAlso es ist nicht der große Wurf,\nden sich manche erhofft hatten, aber ich glaube, wenn man sich das Gesetz anschaut\nund auch wie das Gesetz gemacht ist,\ndann konnte dieses Gesetz auch nie diese Erwartungshaltung erfüllen,\nauch weil KI und automated decision making so viele Bereiche umfasst.\nDas geht eben von biometrischer Massenüberwachung bis KI-Systeme,\ndie kreativ verwendet werden oder die sagen, zu welcher Schule du gehen sollst.\nUnd den Bereich so groß zu spannen, heißt halt auch, man kann nicht ganz oben\nanfangen, sondern es ist quasi ein Minimalkonsens darüber, wie KI-Systeme in\nZukunft gemacht werden sollen.\nAber gerade auch darauf basierend, welche KI-Systeme jetzt schon am Markt sind,\nist es extrem schwierig zu sagen, weil auch da die Anforderungen ja auch viel\nspäter erst in Kraft treten werden.","Aber ganz konkret, wegen Palantir, wenn Palantir genutzt wird,\num über individuelle Personen Vorhersagen zu machen, ob sie irgendwann mal eine\nStraftat begehen, dann muss das jetzt weg.\nDas ist nicht mehr erlaubt in Zukunft, so ganz konkret. Und es soll eben auch,\nwie gesagt, sowas wie diesen niederländischen Sozial-Social-Benefits-Skandal\nda irgendwie in Zukunft vermeiden, helfen.\nEine Sache, die wir noch gar nicht erwähnt hatten, wo wir aber auch ziemlich\ndrauf stolz sind, ist, dass jetzt in Zukunft viele KI-Systeme,\nvor allem die Allzwecksysteme, auch Energiebilanzen offenlegen müssen.\nDas Zeug verbraucht ja unglaublich viel Strom und auch Wasser.\nDas muss jetzt offengelegt werden, mindestens für die General-Purpose-KIs. Da bin ich mal gespannt.\nAlso Ökobilanzen und so haben wir jetzt auch drin. Auch einer unserer Erfolge.","Das ist eine gute Regelung. Da bin ich auch gespannt, wie das ausgeht.\nOb man das überhaupt so berechnet bekommt. Wahrscheinlich schon irgendwie.","Das kannst du einfach berechnen. Du hast irgendwie so viele Millionen Videokarten\nund guckst halt, was die dann Strom verbrauchen. Das ist nicht so schwer.","Ja, ist klar. Gut, ich denke, den AI-Act-Teil können wir damit beschließen, oder?","Ich glaube auch, wenn es von eurer Seite nichts mehr gibt, dann,\nwir sind schon relativ lange, deswegen machen wir das jetzt vielleicht sehr kurz.\nIch wollte nur nochmal so einen Ausblick auf die EU generell.\nIhr sitzt ja auch weiter in Brüssel und seid da sehr nah dran und wir haben jetzt ein paar.","Wir sind mittendrin.","Genau, statt nur dabei und habe da ja auch wirklich auch, es heißt ja irgendwie\nso schön, dass das Herstellen von Würsten, von Sausages und das Gesetze machen,\nda will man nicht so genau wissen, wie es wirklich passiert und gleichzeitig\nist die EU auch gerade am Ende ihrer Legislaturperiode, im Juni sind Wahlen.\nMan hat auch, glaube ich, gesehen, dass ganz viele netzpolitische Themen dann\nam Ende an den Mehrheitsverhältnissen im Parlament und natürlich auch in den\nnationalen Regierungen hängen.\nUnd ja, nach allen Vorhersagen wird es einen Rechtsrott geben im Europaparlament.\nDas heißt, es wird eine Mehrheit geben aus den Fraktionen ID,\nwas AfD, FPÖ ist, ECR, also die europaskeptischen Konservativen bis Rechtsextreme in manchen Fällen.\nUnd halt auch der Europäischen Volkspartei.\nUnd das wird natürlich, glaube ich, dann auch so diese Schlagzahl der Gesetze,\nvor allem wenn es darum geht, Harmonisierungen durchzuführen.\nWahrscheinlich reduzieren.\nWas manchmal vielleicht sogar ganz gut wäre, wenn man sich mehr Zeit nimmt für\ndie Gesetze, schaut, dass man wirklich eine breite Mehrheit hat.\nInsgesamt ist mein Eindruck, auch wenn ich euch heute so zugehört habe,\ndass ganz viel am Zeitdruck liegt.\nDass etwas unbedingt bis dahin fertig werden muss und dann sind halt irgendwie\ndrei Viertel der Leute schon auf Urlaub und Ralf muss irgendwie aus dem Ferienhaus\nheraus dann das fertig verhandeln.\nDas kann es ja nicht sein. Also ich meine, wenn sich Europa ernst nimmt,\ndann muss man den Gesetzestext vor sich haben ausverhandelt und dann entscheiden,\nob der eine Mehrheit hat.\nAlso ganz oft tut einem das ja schon beim Zuhören und Zuschauen weh,\nwie dann wirklich diese Entscheidungen, wie stümperhaft diese Entscheidungen zustande kommen.\nAber ja, wie geht es euch damit und wie schaut ihr jetzt so auf die Zeit nach der Wahl?","Vielleicht zu der ersten Frage, wie laufen sozusagen diese Trilogverhandlungen?\nIst das wirklich immer so schlimm?\nAls wir die Datenschutz-Grundverordnung damals verhandelt haben,\nhaben wir wirklich den Text vor uns gehabt. Der wurde auf meinem Laptop mitprotokolliert,\nje nach Verhandlungsstand.\nUnd am Ende des letzten Triloges, das war auch so nachts um elf,\naber immer noch eine halbwegs menschenwürdige Zeit, hatten wir einen fertigen Text.\nText, der muss dann ein paar Mal noch horizontal angepasst werden,\ndas haben wir dann noch kurz danach noch gemacht in meinem Büro und der konnte\ndann direkt an die Mitgliedstaaten rausgehen und auch an alle Abgeordneten, die beteiligt waren.\nDas habe ich jetzt ein paar Mal erlebt, dass das nicht so gelaufen ist.\nMal gucken, wie es morgen Nacht wird bei den Gesundheitsdaten,\nob wir da einen finalen Text haben, da ist es zumindest ein bisschen besser,\ndass jetzt schon mal Textentwürfe vorher flottieren.\nBeim AI-Hack war es einfach wirklich chaotisch, wir hatten beim letzten Trilog,\nals der anfing, noch 22 Punkte offen, haben dann wirklich von Nachmittags um\ndrei die ganze Nacht durch bis zum nächsten Mittag um eins verhandelt,\ndann eine Pause gemacht,\neinmal schlafen können die Nacht dann und am Freitag um acht Uhr morgens ging\nes schon wieder weiter bis nach Mitternacht.\nUnd da gab es dann einfach teilweise keine Texte. Ich habe von anderen Trilogen\ngehört, wo es teilweise nur so Bullet-Point-Listen gab, auf was man sich jetzt\ngeeinigt hat, wo dann die technische Ebene hinterher noch einen Monat beschäftigt\nwar, das auszuformulieren.\nDa hat, glaube ich, die Qualität echt ein bisschen gelitten in letzter Zeit, ist so mein Eindruck.\nDa gibt es aber jetzt auch schon eine Reaktion drauf und zumindest vom Parlament\naus gibt es jetzt offenbar Bestrebungen, ein interinstitutionelles Abkommen\nzu verhandeln mit dem Rat und der Kommission, wie genau so Triloge eigentlich geführt werden müssen.\nWeil das oft immer noch sehr informell ist, die sind ja auch in den Verträgen irgendwo vorgesehen.\nIch bin trotzdem der Meinung, man braucht so einen geschützten Raum,\nwenn man sich auf irgendwelche Texte einigen will. Da muss man halt die Köpfe\nzusammenstecken mit Ausschluss der Öffentlichkeit.\nAber das braucht zumindest ein paar Regeln. Und da soll jetzt hoffentlich nach\nder Wahl mit den anderen Institutionen daran gearbeitet werden.","Annika, wie siehst du das?","Ich glaube, das Problem war auch jetzt beim KI-Gesetz die einfache Unmenge an\nGesetzen, die jetzt noch verabschiedet werden sollten vor Ende der Legislaturperiode.\nUnd die Angst, die halt irgendwo immer auch mitgeschwungen ist,\nist, was, wenn wir dieses Gesetz eben nicht, dieses Mandat fertig kriegen.\nWas bedeutet das dann mit einem deutlich rechteren Parlament?\nKriegen wir da noch die Punkte, die uns wirklich wichtig sind, durch?\nUnd vor allem auch im Hinblick darauf, dass eben Ungarn auch die nächste Ratspräsidentschaft\nnach Belgien jetzt hat und damit dann viele von den Prioritäten,\ndie wir hatten, was Menschenrechte betrifft, sehr unwahrscheinlich gewesen wären.\nDas heißt, es hätte sich noch weiter verzögert und dann wären wir im Jahr 2025\ngewesen, wo wir dann wieder angefangen hätten, an KI-Gesetzen zu arbeiten und\ndann sind wir halt auch keine Vorreiter mehr.\nAlso dann hätten wir eigentlich vielleicht sogar das Gesetz nochmal komplett\nneu machen müssen. Also das ist halt immer mit geschwungen, aber ich gebe grundsätzlich\nrecht, dass die Tatsache, dass wir keinen finalen Text hatten,\ndas war einfach unglaublich. Und wir haben auch wirklich drum gebettelt.\nUnd das war einfach dann auch vielleicht der Zeit geschuldet,\ndie wir da gesessen sind, ist dann einfach ausgerufen worden,\ndass es einen Deal gibt und dann haben sich halt auch Politiker mitreißen lassen.\nDiesen Deal einfach dann festzusetzen.\nUnd ja, ich finde das auch super problematisch und ich hoffe auch,\ndass es in Zukunft besser läuft.\nIch weiß auch, dass wir uns in dem Ausschuss, der sich eben mit den ganzen Prozessen\nbeschäftigt und den Rules of Procedure dafür einsetzen, dass es eben auch bessere\nRegeln in den Trilogen gibt, dass es auch etwas mehr Transparenz gibt.\nAlso es muss nicht unbedingt einen Livestream geben, aber dass gewisse Dokumente\nauch etwas transparenter sind.\nUnd das hoffe ich mir für die Zukunft auch eben auch, um das Vertrauen in die\nEU-Institutionen auch zu verbessern.\nAbsolut.","Ich glaube, der Zugang zu Texten, ich meine, ich habe die ja dann oft über Kanäle,\naber dass das nicht öffentlich ist, ist wirklich ein Unding.\nWas in Parlamenten diskutiert wird, sollte öffentlich sein.\nUnd ein Vorschlag für diese Regeln, die ihr euch geben wollt,\nes würde schon sehr viel helfen, wenn Europaabgeordnete sich nicht bereit erklären,\nauf irgendwelchen Fotos mit der Kommission und der Ratspräsidentschaft zu sein,\nbis der Text wirklich ausverhandelt ist.\nWeil oft ist es so irgendwie das getwitterte Foto und jetzt sind wir fertig\nund dann stehen alle auf und glauben, dass sie wirklich fertig sind,\nauch wenn danach noch ganz viel wegverhandelt wird.\nDas haben wir leider ein paar Mal gesehen und das ist nur ein billiger Trick.\nIch hoffe, das war heute trotzdem eine Sendung, die nicht nur traurig zurücklässt,\nsondern ein bisschen aufgezeigt hat.","Cyber, Cyber, alles gut.","Aber jetzt will ich noch wissen, hilft euch denn AI sozusagen auch bei der Analyse\ndieser ganzen Textvorschläge?\nIch meine, ihr seid ja auch die ganze Zeit so in diesem Business mit,\nihr kriegt so viel Text zugeschickt und permanent müsst ihr irgendwie verstehen,\nwas da jetzt eigentlich mit gemeint ist.\nKommt da sozusagen auch schon die LLM zum Einsatz oder macht ihr das alles noch von Hand?","Welcher Teil von May I Act wurde von ChatGPT geschrieben?","Also ich kann sagen, das einzige Mal, wo ich in meinem Leben Chachapiti verwendet\nhabe, um mit meinem Freund zu brainstormen, welche Hundenamen wir uns überlegen möchten.\nIch schwöre. Also wir haben alle Texte selber gelesen und selber analysiert\nund es waren sehr, sehr viele Texte.\nAber die Versuchung ist natürlich groß, aber es spielt eigentlich nicht wirklich\neine Rolle, weil gerade diese Texte so spezifisch sind und so technisch und so kontextbasiert,\ndass es schwierig wäre und ich finde auch ethisch problematisch,\ndas durch irgendeine KI zu jagen.","Ja, okay.\nMan kann es ja auch...\nGanz praktisch sehen, einfach als Tool, also ich gebe zu,\ndass jetzt zum Beispiel auch gemacht zu haben, ich nehme mir so einen kompletten Text,\nden ich jetzt, wenn ich den lesen würde, ohnehin nicht verstehen würde,\nweil mir einfach das juristische Modell dafür fehlt und die Dingertaugung sicherlich\nfür vieles nicht, aber dieses Text zusammenfassen, das kriegen die schon irgendwie ganz gut hin.\nUnd dann kann man halt zumindest schon mal reinstochern und sagen so,\nwird da etwas erwähnt zu dem und dem und so weiter und das ja,\ndas sind schon mal ganz hilfreiche Ansätze für mich, aber dass ihr das professioneller\nhandhabt, daran habe ich keinen Zweifel.","Word und solche Software kann ja Auto-Summarize schon länger,\nda brauchst du keinen Chatbot für.\nAber unser Job ist halt leider nicht nur die Zusammenfassung zu machen,\nsondern das Ding im Detail zu lesen und zu verstehen und umzuschreiben,\nda kommt einfach kein Weg dran vorbei.","Na klar. Na gut, dafür seid ihr ja auch hier die Profis.\nVielen, vielen Dank für eure Ausführungen und natürlich auch für eure Arbeit an den Gesetzeswerken.\nDas ist ja mit wenig Urlaub gesegnet, wie wir gerade gehört haben.\nUnd ja, das ist ja eine Entbehrung. Dann kriegst du vielleicht den nächsten\nneuen Eintrag, Annika, auch bei der IMDB, wenn du dann wieder in Hollywood-Fußstapfen steigst.","Ja, danke euch für die Einladung.","Danke auch von meiner Seite und bitte weitermachen und bis zum nächsten Mal.","Danke. Alles klar, das war's heute vom Logbuch Netzpolitik.\nBald geht's wieder weiter, dann vielleicht auch wieder mit Linus.\nWir sagen tschüss und bis bald."]}